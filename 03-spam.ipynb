{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n3lnWjvI83ix"
   },
   "source": [
    "# Filtado de mensajes spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del problema real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La recepción de publicidad no deseada a traves mensajes de texto usando SMS (Short Message Service) es un problema que afecta a muchos usuarios de teléfonos móviles. El problema radica en que los usuarios deben pagar por los mesajes recibidos, y por este motivo resulta muy importante que las compañías prestadoras del servicio puedan filtrar mensajes indeseados antes de enviarlos a su destinatario final. Los mensajes tienen una longitud máxima de 160 caracteres, por lo que el texto resulta poco para realizar la clasificación, en comparación con textos más largos (como los emails). Adicionalmente, los errores de digitación dificultan el proceso de detección automática."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del problema en términos de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tiene una muestra contiene 5574 mensajes en inglés, no codificados y clasificados como legítimos (ham) o spam (http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/). La información está almacenada en el archivo `datos/spam-sms.zip`.El problema en términos de los datos consiste en clasificar si un mensaje SMS es legítico o spam, a partir del análisis de las palabras que contiente, partiendo del supuesto de que ciertas palabras que son más frecuentes dependiendo del tipo de mensaje. Esto implica que en la fase de preparación de los datos se deben extraer las palabras que contiene cada mensaje para poder realizar el análsis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aproximaciones posibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, se desea comparar los resultados de un modelo de redes neuronales artificiales y otras técnicas estadísticas para realizar la clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requerimientos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usted debe:\n",
    "\n",
    "* Preprocesar los datos para representarlos usando bag-of-words.\n",
    "\n",
    "\n",
    "* Construir un modelo de regresión logística como punto base para la comparación con otros modelos más complejos.\n",
    "\n",
    "\n",
    "* Construir un modelo de redes neuronales artificiales. Asimismo, debe determinar el número de neuronas en la capa o capas ocultas.\n",
    "\n",
    "\n",
    "* Utiizar una técnica como crossvalidation u otra similar para establecer la robustez del modelo.\n",
    "\n",
    "\n",
    "* Presentar métricas de desempeño para establecer las bondades y falencias de cada clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix as confusion\n",
    "from sklearn.metrics import accuracy_score as precision\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.model_selection import KFold as KF\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.DataFrame(columns=['etiqueta','contenido'])\n",
    "\n",
    "def limpieza(txt):\n",
    "    return re.sub(\"\\s{1,}\",\" \",re.sub('[0-9]*', '', re.sub('https?:\\/\\/.*[\\n]*','', txt))).replace('&gt;','').replace('&lt;','').translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "with open('datos/SMSSpamCollection.txt', encoding='utf-8') as abierto:\n",
    "    lista = str(abierto.read()).split(\"\\n\")\n",
    "    for row in lista:\n",
    "        patron = \"ham\\s\"\n",
    "        remplazo = \"1,,. \"\n",
    "        row = re.sub(patron, remplazo, row)\n",
    "        patron = \"spam\\s\"\n",
    "        remplazo = \"0,,. \"\n",
    "        row = re.sub(patron, remplazo, row)\n",
    "        row = row.split(\",,.\")\n",
    "        if(len(row)>1):\n",
    "            datos = datos.append({\n",
    "                'etiqueta': row[0],\n",
    "                'contenido': limpieza(row[1]) \n",
    "                }, ignore_index=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de palabras no significativas y creción de la bolsa de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datos['contenido']\n",
    "Y = datos['etiqueta'].astype('int')\n",
    "\n",
    "stem = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "## palabras propias del lenguaje sin aporte al análiss\n",
    "propias = stopwords.words(\"english\")\n",
    "def aplicarStem(txt):   \n",
    "   \n",
    "    words = [stem.stem(word) for word in txt.split() if word.lower() not in propias]\n",
    "    return \" \".join(words)\n",
    "\n",
    "ss = []\n",
    "for i in X:\n",
    "    ss.append(aplicarStem(i))\n",
    "\n",
    "# Bolsa de palabras\n",
    "\n",
    "vectorizador = CountVectorizer(ss)\n",
    "sX = vectorizador.fit_transform(ss)\n",
    "\n",
    "sX = sX.toarray()\n",
    "X_train, X_test, Y_train, Y_test = tts(sX, Y , stratify = Y, test_size = 0.2, random_state=101)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:  [[129  20]\n",
      " [  2 964]] \n",
      " Precisión:  0.9802690582959641\n"
     ]
    }
   ],
   "source": [
    "regresion = LogisticRegression()\n",
    "regresion.fit(X_train, Y_train)\n",
    "prediccion = regresion.predict(X_test)\n",
    "\n",
    "print(\n",
    "      \"Matriz de confusión: \", confusion(Y_test, prediccion),\n",
    "      \"\\n\",\n",
    "      \"Precisión: \",precision(Y_test, prediccion)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se elige la cantidad de neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 7133      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 7,135\n",
      "Trainable params: 7,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.6043 - acc: 0.8623\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 116us/sample - loss: 0.4358 - acc: 0.8659\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 119us/sample - loss: 0.3299 - acc: 0.8659\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.2703 - acc: 0.8659\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.2338 - acc: 0.8659\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 121us/sample - loss: 0.2094 - acc: 0.8659\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 129us/sample - loss: 0.1911 - acc: 0.8659\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 118us/sample - loss: 0.1764 - acc: 0.8659\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.1640 - acc: 0.8659\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 130us/sample - loss: 0.1530 - acc: 0.8659\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 120us/sample - loss: 0.1429 - acc: 0.8659\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 128us/sample - loss: 0.1335 - acc: 0.8659\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 129us/sample - loss: 0.1245 - acc: 0.9832\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 164us/sample - loss: 0.1162 - acc: 0.9874\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 130us/sample - loss: 0.1082 - acc: 0.9890\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 0.1007 - acc: 0.9915\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 132us/sample - loss: 0.0937 - acc: 0.9926\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 0.0871 - acc: 0.9935\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 169us/sample - loss: 0.0810 - acc: 0.9942\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 147us/sample - loss: 0.0752 - acc: 0.9953\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 0.0699 - acc: 0.9957\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 0.0650 - acc: 0.9960\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 0.0604 - acc: 0.9964\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 0.0562 - acc: 0.9964\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 158us/sample - loss: 0.0523 - acc: 0.9964\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0487 - acc: 0.9969\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 147us/sample - loss: 0.0454 - acc: 0.9971\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 146us/sample - loss: 0.0423 - acc: 0.9973\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 128us/sample - loss: 0.0395 - acc: 0.9975\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 131us/sample - loss: 0.0368 - acc: 0.9978\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 128us/sample - loss: 0.0344 - acc: 0.9980\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 119us/sample - loss: 0.0322 - acc: 0.9980\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.0301 - acc: 0.9980\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 122us/sample - loss: 0.0282 - acc: 0.9980\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 120us/sample - loss: 0.0264 - acc: 0.9982\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 119us/sample - loss: 0.0247 - acc: 0.9984\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 123us/sample - loss: 0.0232 - acc: 0.9984\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 132us/sample - loss: 0.0217 - acc: 0.9989\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 0.0204 - acc: 0.9989\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 146us/sample - loss: 0.0192 - acc: 0.9989\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 130us/sample - loss: 0.0180 - acc: 0.9989\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 123us/sample - loss: 0.0169 - acc: 0.9989\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 121us/sample - loss: 0.0159 - acc: 0.9991\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 121us/sample - loss: 0.0149 - acc: 0.9993\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 121us/sample - loss: 0.0140 - acc: 0.9993\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 121us/sample - loss: 0.0132 - acc: 0.9993\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 121us/sample - loss: 0.0124 - acc: 0.9993\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 118us/sample - loss: 0.0117 - acc: 0.9993\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 119us/sample - loss: 0.0110 - acc: 0.9993\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 120us/sample - loss: 0.0103 - acc: 0.9993\n",
      "1115/1115 [==============================] - 0s 114us/sample - loss: 0.1143 - acc: 0.9767\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 2)                 14266     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 14,269\n",
      "Trainable params: 14,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 161us/sample - loss: 0.5740 - acc: 0.8636\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 0.3664 - acc: 0.8659\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 146us/sample - loss: 0.2660 - acc: 0.8659\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.2169 - acc: 0.8659\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.1881 - acc: 0.8659\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 132us/sample - loss: 0.1684 - acc: 0.8659\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.1533 - acc: 0.8659\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 157us/sample - loss: 0.1410 - acc: 0.8659\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 0.1301 - acc: 0.8798\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 151us/sample - loss: 0.1202 - acc: 0.9861\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459/4459 [==============================] - 1s 155us/sample - loss: 0.1111 - acc: 0.9879\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 159us/sample - loss: 0.1027 - acc: 0.9913\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 167us/sample - loss: 0.0950 - acc: 0.9928s - loss: 0.0957 - acc: 0\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 168us/sample - loss: 0.0879 - acc: 0.9939\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 171us/sample - loss: 0.0813 - acc: 0.9955\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0753 - acc: 0.9960\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 0.0696 - acc: 0.9964\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0645 - acc: 0.9964\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0598 - acc: 0.9964\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 131us/sample - loss: 0.0554 - acc: 0.9971\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 132us/sample - loss: 0.0514 - acc: 0.9975\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 134us/sample - loss: 0.0477 - acc: 0.9975\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 129us/sample - loss: 0.0443 - acc: 0.9978\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0412 - acc: 0.9980\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0383 - acc: 0.9980\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 0.0357 - acc: 0.9980\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 164us/sample - loss: 0.0332 - acc: 0.9982\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 164us/sample - loss: 0.0310 - acc: 0.9989\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 159us/sample - loss: 0.0288 - acc: 0.9989\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0269 - acc: 0.9989\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0251 - acc: 0.9989\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - ETA: 0s - loss: 0.0238 - acc: 0.998 - 1s 139us/sample - loss: 0.0234 - acc: 0.9989\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 0.0219 - acc: 0.9989\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 177us/sample - loss: 0.0204 - acc: 0.9993\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 151us/sample - loss: 0.0191 - acc: 0.9993\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 147us/sample - loss: 0.0178 - acc: 0.9993\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 0.0167 - acc: 0.9993\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 172us/sample - loss: 0.0156 - acc: 0.9993\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0146 - acc: 0.9993\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 161us/sample - loss: 0.0136 - acc: 0.9993\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 132us/sample - loss: 0.0128 - acc: 0.9996\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 132us/sample - loss: 0.0120 - acc: 0.9996\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 130us/sample - loss: 0.0112 - acc: 0.9996\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 0.0105 - acc: 0.9996\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 132us/sample - loss: 0.0099 - acc: 0.9996\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 128us/sample - loss: 0.0093 - acc: 0.9996\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 146us/sample - loss: 0.0087 - acc: 0.9996\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0082 - acc: 0.9996\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0077 - acc: 0.9996\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 133us/sample - loss: 0.0072 - acc: 0.9996\n",
      "1115/1115 [==============================] - 0s 109us/sample - loss: 0.1255 - acc: 0.9776\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 3)                 21399     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 21,403\n",
      "Trainable params: 21,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 147us/sample - loss: 0.5215 - acc: 0.8937\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 146us/sample - loss: 0.2840 - acc: 0.9569\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 0.1752 - acc: 0.9733\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.1183 - acc: 0.9823\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0857 - acc: 0.9877\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 122us/sample - loss: 0.0653 - acc: 0.9899\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.0515 - acc: 0.9926\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0419 - acc: 0.9935\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 0.0347 - acc: 0.9948\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 0.0293 - acc: 0.9957\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0251 - acc: 0.9960\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0218 - acc: 0.9960\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0191 - acc: 0.9960\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0170 - acc: 0.9969\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 0.0151 - acc: 0.9971\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0135 - acc: 0.9973\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0122 - acc: 0.9973\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 128us/sample - loss: 0.0111 - acc: 0.9973\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 0.0101 - acc: 0.9975\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 0.0093 - acc: 0.9980\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 123us/sample - loss: 0.0086 - acc: 0.9980\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0079 - acc: 0.9980\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 128us/sample - loss: 0.0073 - acc: 0.9982\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0067 - acc: 0.9982\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 128us/sample - loss: 0.0062 - acc: 0.9982\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.0058 - acc: 0.9982\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0054 - acc: 0.9984\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 128us/sample - loss: 0.0050 - acc: 0.9984\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 130us/sample - loss: 0.0047 - acc: 0.9984\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 0.0044 - acc: 0.9987\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 157us/sample - loss: 0.0041 - acc: 0.9987\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 0.0039 - acc: 0.9987\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 176us/sample - loss: 0.0036 - acc: 0.9987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 159us/sample - loss: 0.0034 - acc: 0.9987\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0032 - acc: 0.9987\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0031 - acc: 0.9987\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 123us/sample - loss: 0.0029 - acc: 0.9987\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.0028 - acc: 0.9987\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 146us/sample - loss: 0.0026 - acc: 0.9987\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0025 - acc: 0.9987\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0024 - acc: 0.9987\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0023 - acc: 0.9987\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0022 - acc: 0.9987\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0021 - acc: 0.9987\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0020 - acc: 0.9987\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 134us/sample - loss: 0.0019 - acc: 0.9987\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0018 - acc: 0.9991\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 146us/sample - loss: 0.0017 - acc: 0.9991\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 159us/sample - loss: 0.0016 - acc: 0.9991\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 148us/sample - loss: 0.0016 - acc: 0.9991\n",
      "1115/1115 [==============================] - 0s 132us/sample - loss: 0.1023 - acc: 0.9803\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 4)                 28532     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 28,537\n",
      "Trainable params: 28,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 148us/sample - loss: 0.5116 - acc: 0.8684\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 130us/sample - loss: 0.2777 - acc: 0.9430\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.1692 - acc: 0.9704\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 130us/sample - loss: 0.1109 - acc: 0.9818\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 131us/sample - loss: 0.0783 - acc: 0.9879\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 132us/sample - loss: 0.0587 - acc: 0.9904\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 132us/sample - loss: 0.0458 - acc: 0.9926\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 134us/sample - loss: 0.0369 - acc: 0.9942\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0304 - acc: 0.9960\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 129us/sample - loss: 0.0256 - acc: 0.9962\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 133us/sample - loss: 0.0218 - acc: 0.9962\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0188 - acc: 0.9964\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 0.0163 - acc: 0.9969\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 162us/sample - loss: 0.0144 - acc: 0.9975\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 175us/sample - loss: 0.0127 - acc: 0.9975\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0114 - acc: 0.9975\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 0.0102 - acc: 0.9975\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0093 - acc: 0.9980\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 134us/sample - loss: 0.0084 - acc: 0.9980\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0077 - acc: 0.9982\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0070 - acc: 0.9982\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0064 - acc: 0.9982\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 0.0059 - acc: 0.9984\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 134us/sample - loss: 0.0054 - acc: 0.9987\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0050 - acc: 0.9989\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 129us/sample - loss: 0.0046 - acc: 0.9989\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0043 - acc: 0.9989\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0040 - acc: 0.9989\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0037 - acc: 0.9991\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 147us/sample - loss: 0.0035 - acc: 0.9991\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0032 - acc: 0.9991\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 131us/sample - loss: 0.0030 - acc: 0.9991\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 131us/sample - loss: 0.0028 - acc: 0.9991\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 129us/sample - loss: 0.0027 - acc: 0.9991\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 131us/sample - loss: 0.0025 - acc: 0.9991\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 132us/sample - loss: 0.0023 - acc: 0.9991\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 130us/sample - loss: 0.0022 - acc: 0.9991\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 134us/sample - loss: 0.0021 - acc: 0.9991\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 157us/sample - loss: 0.0020 - acc: 0.9991\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0018 - acc: 0.9991\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 192us/sample - loss: 0.0017 - acc: 0.9991A: 0s - loss: 0.0018 - ac\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 209us/sample - loss: 0.0016 - acc: 0.9991\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 0.0015 - acc: 0.9991\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0015 - acc: 0.9991\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 167us/sample - loss: 0.0014 - acc: 0.9991\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 175us/sample - loss: 0.0013 - acc: 0.9996\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.0012 - acc: 0.9996\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0012 - acc: 0.9996\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 119us/sample - loss: 0.0011 - acc: 0.9996\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 121us/sample - loss: 0.0011 - acc: 0.9996\n",
      "1115/1115 [==============================] - 0s 113us/sample - loss: 0.1090 - acc: 0.9812\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 5)                 35665     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 35,671\n",
      "Trainable params: 35,671\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 155us/sample - loss: 0.5268 - acc: 0.9159\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 123us/sample - loss: 0.2620 - acc: 0.9711\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.1464 - acc: 0.9812\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 117us/sample - loss: 0.0942 - acc: 0.9877\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 0s 111us/sample - loss: 0.0666 - acc: 0.9899\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 0s 112us/sample - loss: 0.0502 - acc: 0.9924\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 115us/sample - loss: 0.0393 - acc: 0.9944\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 113us/sample - loss: 0.0318 - acc: 0.9960\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 121us/sample - loss: 0.0263 - acc: 0.9960\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0221 - acc: 0.9962\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0190 - acc: 0.9966\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 0.0165 - acc: 0.9973\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 0.0145 - acc: 0.9973\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.0128 - acc: 0.9973\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0114 - acc: 0.9978\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0103 - acc: 0.9978\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 131us/sample - loss: 0.0093 - acc: 0.9978\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 118us/sample - loss: 0.0085 - acc: 0.9980\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 114us/sample - loss: 0.0077 - acc: 0.9980\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0071 - acc: 0.9980\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 115us/sample - loss: 0.0065 - acc: 0.9982\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 116us/sample - loss: 0.0060 - acc: 0.9984\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 119us/sample - loss: 0.0056 - acc: 0.9984\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 119us/sample - loss: 0.0052 - acc: 0.9987\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 116us/sample - loss: 0.0048 - acc: 0.9987\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 120us/sample - loss: 0.0045 - acc: 0.9987\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 0.0042 - acc: 0.9987\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 0.0040 - acc: 0.9987\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 0.0038 - acc: 0.9987\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 129us/sample - loss: 0.0036 - acc: 0.9987\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0034 - acc: 0.9987\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0032 - acc: 0.9987\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 116us/sample - loss: 0.0031 - acc: 0.9987\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 170us/sample - loss: 0.0029 - acc: 0.9987\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 173us/sample - loss: 0.0028 - acc: 0.9987A: 0s - loss: 0.0037 - a\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 204us/sample - loss: 0.0027 - acc: 0.9987\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 172us/sample - loss: 0.0026 - acc: 0.9987\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 0.0025 - acc: 0.9987\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 197us/sample - loss: 0.0024 - acc: 0.9987\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 158us/sample - loss: 0.0023 - acc: 0.9987\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0022 - acc: 0.9987\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 146us/sample - loss: 0.0021 - acc: 0.9987\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0020 - acc: 0.9987\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0019 - acc: 0.9987\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0019 - acc: 0.9987\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0018 - acc: 0.9987\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 146us/sample - loss: 0.0017 - acc: 0.9989\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0017 - acc: 0.9989\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 130us/sample - loss: 0.0016 - acc: 0.9989\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 147us/sample - loss: 0.0015 - acc: 0.9989\n",
      "1115/1115 [==============================] - 0s 200us/sample - loss: 0.1060 - acc: 0.9821\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 6)                 42798     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 42,805\n",
      "Trainable params: 42,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 168us/sample - loss: 0.4723 - acc: 0.8659\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.2469 - acc: 0.8659\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 0.1819 - acc: 0.8659\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 151us/sample - loss: 0.1520 - acc: 0.8659\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 160us/sample - loss: 0.1334 - acc: 0.8659\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.1194 - acc: 0.9773\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 0.1080 - acc: 0.9892\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 0.0982 - acc: 0.9928\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 164us/sample - loss: 0.0896 - acc: 0.9957\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 131us/sample - loss: 0.0821 - acc: 0.9962\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.0753 - acc: 0.9969\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 134us/sample - loss: 0.0693 - acc: 0.9973\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.0637 - acc: 0.9975\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 123us/sample - loss: 0.0586 - acc: 0.9980\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 0.0541 - acc: 0.9980\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0499 - acc: 0.9982\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.0460 - acc: 0.9987\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0425 - acc: 0.9989\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 128us/sample - loss: 0.0393 - acc: 0.9989\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 0.0363 - acc: 0.9991\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 134us/sample - loss: 0.0337 - acc: 0.9993\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 129us/sample - loss: 0.0312 - acc: 0.9993\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0289 - acc: 0.9993\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0268 - acc: 0.9996\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0249 - acc: 0.9996\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 0.0231 - acc: 0.9996\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 0.0215 - acc: 0.9996\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0200 - acc: 0.9996\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 157us/sample - loss: 0.0186 - acc: 0.9996\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 162us/sample - loss: 0.0174 - acc: 0.9996\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 167us/sample - loss: 0.0162 - acc: 0.9996\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 0.0151 - acc: 0.9996\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 128us/sample - loss: 0.0141 - acc: 0.9998\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0131 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0123 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0100 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0094 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 162us/sample - loss: 0.0077 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0072 - acc: 1.0000s - loss: 0.0075 - a\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 133us/sample - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 130us/sample - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 128us/sample - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 131us/sample - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 128us/sample - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 0.0046 - acc: 1.0000\n",
      "1115/1115 [==============================] - 0s 128us/sample - loss: 0.1426 - acc: 0.9785\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 7)                 49931     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 8         \n",
      "=================================================================\n",
      "Total params: 49,939\n",
      "Trainable params: 49,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 162us/sample - loss: 0.5177 - acc: 0.9130\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 123us/sample - loss: 0.2438 - acc: 0.9762\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.1323 - acc: 0.9859\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 122us/sample - loss: 0.0838 - acc: 0.9899\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0585 - acc: 0.9922\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 130us/sample - loss: 0.0436 - acc: 0.9948\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0342 - acc: 0.9955\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 117us/sample - loss: 0.0276 - acc: 0.9962\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 114us/sample - loss: 0.0228 - acc: 0.9964\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 114us/sample - loss: 0.0193 - acc: 0.9969\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 114us/sample - loss: 0.0164 - acc: 0.9971\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 118us/sample - loss: 0.0141 - acc: 0.9975\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0122 - acc: 0.9975\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0107 - acc: 0.9980\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 114us/sample - loss: 0.0094 - acc: 0.9982\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 116us/sample - loss: 0.0083 - acc: 0.9982\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 116us/sample - loss: 0.0075 - acc: 0.9982\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0067 - acc: 0.9984\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0061 - acc: 0.9984\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 0.0055 - acc: 0.9987\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 119us/sample - loss: 0.0051 - acc: 0.9991\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 116us/sample - loss: 0.0047 - acc: 0.9991\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 115us/sample - loss: 0.0043 - acc: 0.9991\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 115us/sample - loss: 0.0040 - acc: 0.9991\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 115us/sample - loss: 0.0038 - acc: 0.9991\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 122us/sample - loss: 0.0035 - acc: 0.9991s - loss: 0.0069 - a\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 117us/sample - loss: 0.0033 - acc: 0.9991\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 115us/sample - loss: 0.0031 - acc: 0.9991\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 115us/sample - loss: 0.0030 - acc: 0.9991\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 115us/sample - loss: 0.0028 - acc: 0.9991\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 114us/sample - loss: 0.0027 - acc: 0.9991\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 117us/sample - loss: 0.0025 - acc: 0.9991\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 118us/sample - loss: 0.0024 - acc: 0.9991\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 120us/sample - loss: 0.0023 - acc: 0.9991\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 118us/sample - loss: 0.0022 - acc: 0.9991\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 118us/sample - loss: 0.0021 - acc: 0.9991\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 115us/sample - loss: 0.0020 - acc: 0.9991\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 118us/sample - loss: 0.0019 - acc: 0.9991\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.0019 - acc: 0.9991\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 129us/sample - loss: 0.0018 - acc: 0.9991\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 129us/sample - loss: 0.0017 - acc: 0.9991\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 128us/sample - loss: 0.0016 - acc: 0.9991\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.0016 - acc: 0.9991\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 122us/sample - loss: 0.0015 - acc: 0.9991\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 114us/sample - loss: 0.0014 - acc: 0.9991\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 117us/sample - loss: 0.0014 - acc: 0.9991\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459/4459 [==============================] - 1s 114us/sample - loss: 0.0013 - acc: 0.9991\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0012 - acc: 0.9991\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0012 - acc: 0.9993\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 128us/sample - loss: 0.0011 - acc: 0.9993\n",
      "1115/1115 [==============================] - 0s 130us/sample - loss: 0.1068 - acc: 0.9821\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 8)                 57064     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 57,073\n",
      "Trainable params: 57,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 177us/sample - loss: 0.5615 - acc: 0.9161\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.3000 - acc: 0.9800\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 0.1664 - acc: 0.9879\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.1045 - acc: 0.9906\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0723 - acc: 0.9937\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0536 - acc: 0.9948s - loss: 0.0485 - ac\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0417 - acc: 0.9957\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0336 - acc: 0.9960\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0279 - acc: 0.9962\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0236 - acc: 0.9971\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0203 - acc: 0.9973\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0177 - acc: 0.9975\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0156 - acc: 0.9975\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0138 - acc: 0.9978\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0123 - acc: 0.9978\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0110 - acc: 0.9980\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0099 - acc: 0.9980\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0089 - acc: 0.9980\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0080 - acc: 0.9982\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 134us/sample - loss: 0.0073 - acc: 0.9982\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0067 - acc: 0.9982\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0061 - acc: 0.9982\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0057 - acc: 0.9984\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 0.0053 - acc: 0.9984\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 0.0049 - acc: 0.9984\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 0.0046 - acc: 0.9984\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0044 - acc: 0.9984\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0041 - acc: 0.9984\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0039 - acc: 0.9984\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0037 - acc: 0.9987\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0036 - acc: 0.9987\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0034 - acc: 0.9987\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0033 - acc: 0.9987\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0032 - acc: 0.9987\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0030 - acc: 0.9987\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0029 - acc: 0.9987A: 0s - loss: 0.0010 - acc:\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0028 - acc: 0.9987\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0028 - acc: 0.9987\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0027 - acc: 0.9987\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0026 - acc: 0.9987\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0025 - acc: 0.9987\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0025 - acc: 0.9987\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0024 - acc: 0.9987\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0023 - acc: 0.9987\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0022 - acc: 0.9987\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0021 - acc: 0.9987\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0021 - acc: 0.9987\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 0.0020 - acc: 0.9987\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 0.0019 - acc: 0.9987\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 0.0019 - acc: 0.9987\n",
      "1115/1115 [==============================] - 0s 139us/sample - loss: 0.1013 - acc: 0.9830\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 9)                 64197     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 64,207\n",
      "Trainable params: 64,207\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 186us/sample - loss: 0.4786 - acc: 0.9166\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 0.1974 - acc: 0.9758\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 0.1032 - acc: 0.9863\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 146us/sample - loss: 0.0649 - acc: 0.9910\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0454 - acc: 0.9933\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 0.0337 - acc: 0.9951\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 0.0261 - acc: 0.9962\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0209 - acc: 0.9969\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 0.0172 - acc: 0.9971\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0144 - acc: 0.9975\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0123 - acc: 0.9980\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0106 - acc: 0.9982\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0093 - acc: 0.9982\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0082 - acc: 0.9984\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 0.0073 - acc: 0.9984\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 0.0065 - acc: 0.9987\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0058 - acc: 0.9987\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0052 - acc: 0.9987\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 0.0047 - acc: 0.9989\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0043 - acc: 0.9989\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 0.0040 - acc: 0.9989\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 0.0037 - acc: 0.9989\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 155us/sample - loss: 0.0034 - acc: 0.9989\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 151us/sample - loss: 0.0032 - acc: 0.9989\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 169us/sample - loss: 0.0030 - acc: 0.9989\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 174us/sample - loss: 0.0028 - acc: 0.9989\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 168us/sample - loss: 0.0026 - acc: 0.9989\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 162us/sample - loss: 0.0025 - acc: 0.9989\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 161us/sample - loss: 0.0023 - acc: 0.9989\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 161us/sample - loss: 0.0022 - acc: 0.9989\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 147us/sample - loss: 0.0021 - acc: 0.9989\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 0.0020 - acc: 0.9989\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0019 - acc: 0.9989\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0018 - acc: 0.9989\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0017 - acc: 0.9989\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0016 - acc: 0.9989\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0015 - acc: 0.9989\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0015 - acc: 0.9989\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 0.0014 - acc: 0.9989\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0013 - acc: 0.9989\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 0.0013 - acc: 0.9993\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 0.0012 - acc: 0.9993\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0012 - acc: 0.9993\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0011 - acc: 0.9993\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0011 - acc: 0.9993\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0010 - acc: 0.9993\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 151us/sample - loss: 9.6345e-04 - acc: 0.9993\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 9.2252e-04 - acc: 0.9993\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 8.8875e-04 - acc: 0.9993\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 8.5434e-04 - acc: 0.9993\n",
      "1115/1115 [==============================] - 0s 131us/sample - loss: 0.1174 - acc: 0.9812\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 10)                71330     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 71,341\n",
      "Trainable params: 71,341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 161us/sample - loss: 0.5563 - acc: 0.9107\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.2744 - acc: 0.9805\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 131us/sample - loss: 0.1420 - acc: 0.9879\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 133us/sample - loss: 0.0864 - acc: 0.9919\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 129us/sample - loss: 0.0588 - acc: 0.9944\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0431 - acc: 0.9955\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 122us/sample - loss: 0.0334 - acc: 0.9957\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 120us/sample - loss: 0.0267 - acc: 0.9971\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 122us/sample - loss: 0.0220 - acc: 0.9973\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 123us/sample - loss: 0.0185 - acc: 0.9975\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 0.0157 - acc: 0.9975\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 121us/sample - loss: 0.0136 - acc: 0.9975\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 121us/sample - loss: 0.0118 - acc: 0.9978\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 118us/sample - loss: 0.0104 - acc: 0.9982\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 121us/sample - loss: 0.0092 - acc: 0.9987\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 118us/sample - loss: 0.0082 - acc: 0.9987\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 123us/sample - loss: 0.0074 - acc: 0.9987\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 122us/sample - loss: 0.0066 - acc: 0.9987\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 122us/sample - loss: 0.0060 - acc: 0.9987\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 120us/sample - loss: 0.0055 - acc: 0.9987\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 120us/sample - loss: 0.0051 - acc: 0.9989\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 120us/sample - loss: 0.0047 - acc: 0.9989\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 133us/sample - loss: 0.0044 - acc: 0.9989\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 132us/sample - loss: 0.0041 - acc: 0.9991\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.0038 - acc: 0.9991\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 123us/sample - loss: 0.0036 - acc: 0.9991\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 121us/sample - loss: 0.0034 - acc: 0.9991\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 123us/sample - loss: 0.0032 - acc: 0.9991\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0030 - acc: 0.9991\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 119us/sample - loss: 0.0028 - acc: 0.9991\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.0027 - acc: 0.9991\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 121us/sample - loss: 0.0026 - acc: 0.9991\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 121us/sample - loss: 0.0024 - acc: 0.9991\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 121us/sample - loss: 0.0023 - acc: 0.9991\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 120us/sample - loss: 0.0023 - acc: 0.9991\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459/4459 [==============================] - 1s 122us/sample - loss: 0.0022 - acc: 0.9991\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 119us/sample - loss: 0.0021 - acc: 0.9991\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 122us/sample - loss: 0.0020 - acc: 0.9991\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 122us/sample - loss: 0.0019 - acc: 0.9991\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 123us/sample - loss: 0.0018 - acc: 0.9991\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 118us/sample - loss: 0.0018 - acc: 0.9991\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 122us/sample - loss: 0.0017 - acc: 0.9991\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 120us/sample - loss: 0.0016 - acc: 0.9991\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 123us/sample - loss: 0.0015 - acc: 0.9991\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 130us/sample - loss: 0.0015 - acc: 0.9991\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0014 - acc: 0.9991\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 132us/sample - loss: 0.0014 - acc: 0.9991\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 129us/sample - loss: 0.0013 - acc: 0.9991\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 131us/sample - loss: 0.0012 - acc: 0.9991\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 131us/sample - loss: 0.0012 - acc: 0.9991\n",
      "1115/1115 [==============================] - 0s 136us/sample - loss: 0.1069 - acc: 0.9812\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 11)                78463     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 78,475\n",
      "Trainable params: 78,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 185us/sample - loss: 0.4941 - acc: 0.9215\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - ETA: 0s - loss: 0.2072 - acc: 0.976 - 1s 146us/sample - loss: 0.2056 - acc: 0.9771\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.1042 - acc: 0.9863\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0644 - acc: 0.9915\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 134us/sample - loss: 0.0444 - acc: 0.9942\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 0.0328 - acc: 0.9957\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0253 - acc: 0.9964\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0201 - acc: 0.9966\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 158us/sample - loss: 0.0164 - acc: 0.9971\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 0.0135 - acc: 0.9975\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 0.0113 - acc: 0.9980\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 0.0096 - acc: 0.9987\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 146us/sample - loss: 0.0083 - acc: 0.9987\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 159us/sample - loss: 0.0071 - acc: 0.9987\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 165us/sample - loss: 0.0062 - acc: 0.9987\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 159us/sample - loss: 0.0055 - acc: 0.9989\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 0.0049 - acc: 0.9993\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0043 - acc: 0.9996\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 0.0039 - acc: 0.9996\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0035 - acc: 0.9996\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0032 - acc: 0.9996\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 0.0029 - acc: 0.9996\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0026 - acc: 0.9996\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0024 - acc: 0.9996\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 148us/sample - loss: 0.0022 - acc: 0.9996\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 0.0020 - acc: 0.9996\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 0.0019 - acc: 0.9996\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0017 - acc: 0.9996\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0016 - acc: 0.9996\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0013 - acc: 0.9996\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 0.0012 - acc: 0.9996\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0012 - acc: 0.9996\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0011 - acc: 0.9996\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 9.7444e-04 - acc: 0.9996\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 9.0077e-04 - acc: 0.9998\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 8.2901e-04 - acc: 0.9998\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 7.6477e-04 - acc: 0.9998\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 7.0191e-04 - acc: 0.9998\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 6.4771e-04 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 5.9443e-04 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 5.4647e-04 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 4.9998e-04 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 4.5757e-04 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 4.2027e-04 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 3.8488e-04 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 3.5198e-04 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 3.2382e-04 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 2.9710e-04 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 151us/sample - loss: 2.7519e-04 - acc: 1.0000\n",
      "1115/1115 [==============================] - 0s 159us/sample - loss: 0.1177 - acc: 0.9821\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 12)                85596     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 85,609\n",
      "Trainable params: 85,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459/4459 [==============================] - 1s 170us/sample - loss: 0.5350 - acc: 0.9069\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 131us/sample - loss: 0.2264 - acc: 0.9765\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 0.1098 - acc: 0.9868\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 0.0667 - acc: 0.9913\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 0.0456 - acc: 0.9944\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.0337 - acc: 0.9960\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 129us/sample - loss: 0.0262 - acc: 0.9960\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0210 - acc: 0.9962\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 0.0172 - acc: 0.9966\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0144 - acc: 0.9973\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0122 - acc: 0.9975\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0105 - acc: 0.9980\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.0091 - acc: 0.9982\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0080 - acc: 0.9982\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0071 - acc: 0.9984\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 0.0063 - acc: 0.9984\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0057 - acc: 0.9987\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0051 - acc: 0.9987\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0046 - acc: 0.9987\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 124us/sample - loss: 0.0043 - acc: 0.9987\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 133us/sample - loss: 0.0039 - acc: 0.9989\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0036 - acc: 0.9989\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0033 - acc: 0.9989\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0031 - acc: 0.9991\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0029 - acc: 0.9991\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 0.0027 - acc: 0.9991\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 129us/sample - loss: 0.0025 - acc: 0.9991\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0024 - acc: 0.9991\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0023 - acc: 0.9991\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0021 - acc: 0.9991\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0020 - acc: 0.9991\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 129us/sample - loss: 0.0019 - acc: 0.9991\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 128us/sample - loss: 0.0018 - acc: 0.9991\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 0.0017 - acc: 0.9991\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0016 - acc: 0.9991\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0015 - acc: 0.9991\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 128us/sample - loss: 0.0015 - acc: 0.9991\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 0.0014 - acc: 0.9991\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 128us/sample - loss: 0.0013 - acc: 0.9991\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0013 - acc: 0.9991\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0012 - acc: 0.9993\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 128us/sample - loss: 0.0011 - acc: 0.9993\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 0.0011 - acc: 0.9993\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 0.0010 - acc: 0.9993\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 127us/sample - loss: 9.7467e-04 - acc: 0.9993\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 128us/sample - loss: 9.2852e-04 - acc: 0.9993\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 8.8672e-04 - acc: 0.9996\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 8.4768e-04 - acc: 0.9996\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 125us/sample - loss: 8.1190e-04 - acc: 0.9996\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 126us/sample - loss: 7.8090e-04 - acc: 0.9996\n",
      "1115/1115 [==============================] - 0s 146us/sample - loss: 0.1186 - acc: 0.9812\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 13)                92729     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 92,743\n",
      "Trainable params: 92,743\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 182us/sample - loss: 0.4432 - acc: 0.9303\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 0.1639 - acc: 0.9780\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 162us/sample - loss: 0.0836 - acc: 0.9881\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 158us/sample - loss: 0.0521 - acc: 0.9919\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 0.0359 - acc: 0.9948\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 0.0265 - acc: 0.9962\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0203 - acc: 0.9964\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0161 - acc: 0.9971\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0131 - acc: 0.9980\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 0.0108 - acc: 0.9982\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0092 - acc: 0.9982\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0079 - acc: 0.9984\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0069 - acc: 0.9987\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 148us/sample - loss: 0.0060 - acc: 0.9987\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 0.0053 - acc: 0.9989\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 198us/sample - loss: 0.0047 - acc: 0.9991\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 0.0042 - acc: 0.9993\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0038 - acc: 0.9993\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0035 - acc: 0.9993\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0032 - acc: 0.9993\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 0.0029 - acc: 0.9993\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0025 - acc: 0.9993\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0023 - acc: 0.9993\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0022 - acc: 0.9993\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 0.0020 - acc: 0.9993\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 0.0019 - acc: 0.9993\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 151us/sample - loss: 0.0018 - acc: 0.9993\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 172us/sample - loss: 0.0017 - acc: 0.9993\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 166us/sample - loss: 0.0016 - acc: 0.9993\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 146us/sample - loss: 0.0015 - acc: 0.9993\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0014 - acc: 0.9993\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0013 - acc: 0.9993\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0012 - acc: 0.9993\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 0.0011 - acc: 0.9993\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0011 - acc: 0.9993\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0010 - acc: 0.9993\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 9.5381e-04 - acc: 0.9996\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 9.0428e-04 - acc: 0.9996\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 8.6128e-04 - acc: 0.9996\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 8.1450e-04 - acc: 0.9996\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 7.7845e-04 - acc: 0.9996\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 7.4690e-04 - acc: 0.9996\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 7.1316e-04 - acc: 0.9996\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 6.6849e-04 - acc: 0.9996\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 6.3690e-04 - acc: 0.9996\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 6.0541e-04 - acc: 0.9996\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 5.7833e-04 - acc: 0.9998\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 5.5360e-04 - acc: 0.9998\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 5.3111e-04 - acc: 0.9998\n",
      "1115/1115 [==============================] - 0s 161us/sample - loss: 0.1227 - acc: 0.9821\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 14)                99862     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 99,877\n",
      "Trainable params: 99,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 189us/sample - loss: 0.5011 - acc: 0.9233\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.2046 - acc: 0.9798\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.1016 - acc: 0.9890\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0616 - acc: 0.9926\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0423 - acc: 0.9951\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0314 - acc: 0.9960\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0245 - acc: 0.9962\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0197 - acc: 0.9971\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 0.0162 - acc: 0.9973\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0135 - acc: 0.9975\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0113 - acc: 0.9978\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0097 - acc: 0.9978\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 0.0083 - acc: 0.9980\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 163us/sample - loss: 0.0073 - acc: 0.9984\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 151us/sample - loss: 0.0064 - acc: 0.9987\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0057 - acc: 0.9987\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 0.0052 - acc: 0.9989\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0047 - acc: 0.9989\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0043 - acc: 0.9989\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 147us/sample - loss: 0.0039 - acc: 0.9989\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0037 - acc: 0.9989\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0034 - acc: 0.9991\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0032 - acc: 0.9991\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 0.0030 - acc: 0.9991\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 0.0028 - acc: 0.9991\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 151us/sample - loss: 0.0027 - acc: 0.9991\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 151us/sample - loss: 0.0025 - acc: 0.9991\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 148us/sample - loss: 0.0024 - acc: 0.9991\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 146us/sample - loss: 0.0023 - acc: 0.9991\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0022 - acc: 0.9991\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0021 - acc: 0.9991\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0020 - acc: 0.9991\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0019 - acc: 0.9991\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0018 - acc: 0.9991\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0017 - acc: 0.9991\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0016 - acc: 0.9991\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 146us/sample - loss: 0.0016 - acc: 0.9991\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 0.0015 - acc: 0.9991\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0014 - acc: 0.9991\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0013 - acc: 0.9991\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0013 - acc: 0.9991\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0012 - acc: 0.9991\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0011 - acc: 0.9991\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0011 - acc: 0.9993\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0010 - acc: 0.9993\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 9.7831e-04 - acc: 0.9993\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459/4459 [==============================] - 1s 141us/sample - loss: 9.3604e-04 - acc: 0.9993\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 8.9585e-04 - acc: 0.9993\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 158us/sample - loss: 8.5807e-04 - acc: 0.9993\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 160us/sample - loss: 8.1965e-04 - acc: 0.9993\n",
      "1115/1115 [==============================] - 0s 195us/sample - loss: 0.1177 - acc: 0.9812\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 15)                106995    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 107,011\n",
      "Trainable params: 107,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 184us/sample - loss: 0.4802 - acc: 0.9215\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 0.1738 - acc: 0.9771\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0834 - acc: 0.9881\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 0.0514 - acc: 0.9917\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 0.0356 - acc: 0.9948\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0265 - acc: 0.9960\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0205 - acc: 0.9966\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 146us/sample - loss: 0.0164 - acc: 0.9966\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0133 - acc: 0.9973\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0110 - acc: 0.9980\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0093 - acc: 0.9982\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 0.0080 - acc: 0.9984\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0069 - acc: 0.9984\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 146us/sample - loss: 0.0061 - acc: 0.9989\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0053 - acc: 0.9989\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 147us/sample - loss: 0.0048 - acc: 0.9989\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0043 - acc: 0.9993\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 0.0039 - acc: 0.9993\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 146us/sample - loss: 0.0035 - acc: 0.9993\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 147us/sample - loss: 0.0033 - acc: 0.9993\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 155us/sample - loss: 0.0030 - acc: 0.9993\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 162us/sample - loss: 0.0028 - acc: 0.9993\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 0.0026 - acc: 0.9993\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.0024 - acc: 0.9993\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 147us/sample - loss: 0.0023 - acc: 0.9993\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 163us/sample - loss: 0.0021 - acc: 0.9993\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 165us/sample - loss: 0.0020 - acc: 0.9993\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 165us/sample - loss: 0.0019 - acc: 0.9993\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 164us/sample - loss: 0.0018 - acc: 0.9993\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 164us/sample - loss: 0.0017 - acc: 0.9993\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 163us/sample - loss: 0.0016 - acc: 0.9993\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 163us/sample - loss: 0.0015 - acc: 0.9993\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 166us/sample - loss: 0.0014 - acc: 0.9993\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 170us/sample - loss: 0.0013 - acc: 0.9993\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 166us/sample - loss: 0.0012 - acc: 0.9993\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 168us/sample - loss: 0.0011 - acc: 0.9993\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 168us/sample - loss: 0.0011 - acc: 0.9993\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 163us/sample - loss: 9.9008e-04 - acc: 0.9993\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 166us/sample - loss: 9.2837e-04 - acc: 0.9993\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 169us/sample - loss: 8.7002e-04 - acc: 0.9996\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 167us/sample - loss: 8.2750e-04 - acc: 0.9996\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 7.7393e-04 - acc: 0.9996\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 7.3290e-04 - acc: 0.9996\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 6.9659e-04 - acc: 0.9996\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 158us/sample - loss: 6.5933e-04 - acc: 0.9996\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 6.2749e-04 - acc: 0.9996\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 146us/sample - loss: 5.9913e-04 - acc: 0.9998\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 5.6950e-04 - acc: 0.9998\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 5.4269e-04 - acc: 0.9998\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 5.1882e-04 - acc: 0.9998\n",
      "1115/1115 [==============================] - 0s 157us/sample - loss: 0.1236 - acc: 0.9830\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 16)                114128    \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 114,145\n",
      "Trainable params: 114,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 199us/sample - loss: 0.4650 - acc: 0.9161\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 157us/sample - loss: 0.1636 - acc: 0.9791\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 0.0798 - acc: 0.9892\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 155us/sample - loss: 0.0492 - acc: 0.9926\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 0.0341 - acc: 0.9957\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 0.0255 - acc: 0.9960\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0197 - acc: 0.9969\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0157 - acc: 0.9971\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0127 - acc: 0.9973\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 0.0105 - acc: 0.9980\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 157us/sample - loss: 0.0088 - acc: 0.9987\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 0.0075 - acc: 0.9987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 151us/sample - loss: 0.0065 - acc: 0.9989\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 158us/sample - loss: 0.0057 - acc: 0.9991\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 187us/sample - loss: 0.0050 - acc: 0.9993\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 224us/sample - loss: 0.0045 - acc: 0.9993\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 161us/sample - loss: 0.0040 - acc: 0.9993\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 0.0036 - acc: 0.9993\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0033 - acc: 0.9993\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0030 - acc: 0.9993\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 158us/sample - loss: 0.0028 - acc: 0.9993\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 0.0025 - acc: 0.9993\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 0.0024 - acc: 0.9993\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 157us/sample - loss: 0.0022 - acc: 0.9993\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0020 - acc: 0.9993\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 0.0019 - acc: 0.9993\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0018 - acc: 0.9993\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0017 - acc: 0.9993\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0016 - acc: 0.9993\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 0.0015 - acc: 0.9993\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 155us/sample - loss: 0.0014 - acc: 0.9993\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0013 - acc: 0.9993\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 0.0012 - acc: 0.9993\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0011 - acc: 0.9996\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0010 - acc: 0.9996\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 9.6717e-04 - acc: 0.9996\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 9.0453e-04 - acc: 0.9996\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 175us/sample - loss: 8.4987e-04 - acc: 0.9996\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 176us/sample - loss: 7.9885e-04 - acc: 0.9996\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 165us/sample - loss: 7.4962e-04 - acc: 0.9996\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 7.0807e-04 - acc: 0.9996\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 6.6754e-04 - acc: 0.9996\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 6.2819e-04 - acc: 0.9996\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 5.9504e-04 - acc: 0.9998\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 5.6189e-04 - acc: 0.9998\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 5.3887e-04 - acc: 0.9998\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 5.0771e-04 - acc: 0.9998\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 157us/sample - loss: 4.7628e-04 - acc: 0.9998\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 4.5034e-04 - acc: 0.9998\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 4.2930e-04 - acc: 0.9998\n",
      "1115/1115 [==============================] - 0s 167us/sample - loss: 0.1238 - acc: 0.9812\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 17)                121261    \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 18        \n",
      "=================================================================\n",
      "Total params: 121,279\n",
      "Trainable params: 121,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 194us/sample - loss: 0.4652 - acc: 0.9186\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 161us/sample - loss: 0.1589 - acc: 0.9787\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0763 - acc: 0.9892\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 148us/sample - loss: 0.0465 - acc: 0.9922\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 0.0320 - acc: 0.9955\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 0.0238 - acc: 0.9964\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 0.0185 - acc: 0.9969\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 148us/sample - loss: 0.0147 - acc: 0.9971\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 0.0120 - acc: 0.9978\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 163us/sample - loss: 0.0099 - acc: 0.9978\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 165us/sample - loss: 0.0083 - acc: 0.9984\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0071 - acc: 0.9984\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 0.0061 - acc: 0.9987\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 0.0053 - acc: 0.9989\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 147us/sample - loss: 0.0047 - acc: 0.9991\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 148us/sample - loss: 0.0042 - acc: 0.9991\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 148us/sample - loss: 0.0038 - acc: 0.9993\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 148us/sample - loss: 0.0034 - acc: 0.9993\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 0.0031 - acc: 0.9993\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 0.0028 - acc: 0.9993\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 148us/sample - loss: 0.0026 - acc: 0.9993\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 151us/sample - loss: 0.0024 - acc: 0.9993\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 0.0022 - acc: 0.9993\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 0.0020 - acc: 0.9993\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 151us/sample - loss: 0.0019 - acc: 0.9993\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 0.0017 - acc: 0.9993\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 151us/sample - loss: 0.0016 - acc: 0.9993\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 0.0015 - acc: 0.9993\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 0.0014 - acc: 0.9993\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 148us/sample - loss: 0.0013 - acc: 0.9993\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 0.0012 - acc: 0.9993\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 0.0011 - acc: 0.9993\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 161us/sample - loss: 0.0010 - acc: 0.9993\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 160us/sample - loss: 9.7300e-04 - acc: 0.9996\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459/4459 [==============================] - 1s 157us/sample - loss: 9.0546e-04 - acc: 0.9998\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 158us/sample - loss: 8.4253e-04 - acc: 0.9998\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 7.8406e-04 - acc: 0.9998\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 146us/sample - loss: 7.2695e-04 - acc: 0.9998\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 147us/sample - loss: 6.8127e-04 - acc: 0.9998\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 147us/sample - loss: 6.3939e-04 - acc: 0.9998\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 147us/sample - loss: 6.0029e-04 - acc: 0.9998\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 148us/sample - loss: 5.5968e-04 - acc: 0.9998\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 5.3008e-04 - acc: 0.9998\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 148us/sample - loss: 5.0110e-04 - acc: 0.9998\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 148us/sample - loss: 4.7605e-04 - acc: 0.9998\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 148us/sample - loss: 4.4868e-04 - acc: 0.9998\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 4.2523e-04 - acc: 0.9998\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 163us/sample - loss: 4.0504e-04 - acc: 0.9998\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 168us/sample - loss: 3.8548e-04 - acc: 0.9998\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 158us/sample - loss: 3.6709e-04 - acc: 0.9998\n",
      "1115/1115 [==============================] - 0s 162us/sample - loss: 0.1277 - acc: 0.9821\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 18)                128394    \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 19        \n",
      "=================================================================\n",
      "Total params: 128,413\n",
      "Trainable params: 128,413\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 192us/sample - loss: 0.4528 - acc: 0.9170\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 0.1459 - acc: 0.9767\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 0.0698 - acc: 0.9883\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 166us/sample - loss: 0.0423 - acc: 0.9933\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 170us/sample - loss: 0.0294 - acc: 0.9955\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 160us/sample - loss: 0.0218 - acc: 0.9964\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 0.0169 - acc: 0.9969\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 0.0133 - acc: 0.9973\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0108 - acc: 0.9982\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 148us/sample - loss: 0.0089 - acc: 0.9982\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 151us/sample - loss: 0.0075 - acc: 0.9984\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 148us/sample - loss: 0.0064 - acc: 0.9987\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 168us/sample - loss: 0.0055 - acc: 0.9989\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 160us/sample - loss: 0.0048 - acc: 0.9989\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 0.0042 - acc: 0.9991\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 151us/sample - loss: 0.0037 - acc: 0.9991\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 155us/sample - loss: 0.0033 - acc: 0.9991\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 0.0029 - acc: 0.9993\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0026 - acc: 0.9993s - loss: 0.0025 - a\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 0.0024 - acc: 0.9993\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 0.0022 - acc: 0.9993\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 159us/sample - loss: 0.0020 - acc: 0.9993\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 160us/sample - loss: 0.0018 - acc: 0.9993\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 162us/sample - loss: 0.0016 - acc: 0.9993\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 164us/sample - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 161us/sample - loss: 0.0014 - acc: 0.9996\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 173us/sample - loss: 0.0013 - acc: 0.9996\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 166us/sample - loss: 0.0012 - acc: 0.9996\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 159us/sample - loss: 0.0011 - acc: 0.9998\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 155us/sample - loss: 9.8041e-04 - acc: 0.9998\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 151us/sample - loss: 9.0491e-04 - acc: 0.9998\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 158us/sample - loss: 8.3905e-04 - acc: 0.9998\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 7.8138e-04 - acc: 0.9998\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 7.2620e-04 - acc: 0.9998\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 6.7891e-04 - acc: 0.9998\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 148us/sample - loss: 6.3428e-04 - acc: 0.9998\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 151us/sample - loss: 5.9873e-04 - acc: 0.9998\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 5.6037e-04 - acc: 0.9998\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 151us/sample - loss: 5.2729e-04 - acc: 0.9998\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 4.9731e-04 - acc: 0.9998\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 4.6879e-04 - acc: 0.9998\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 4.4540e-04 - acc: 0.9998\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 4.2376e-04 - acc: 0.9998\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 4.0324e-04 - acc: 0.9998\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 3.8245e-04 - acc: 0.9998\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 3.6509e-04 - acc: 0.9998\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 3.4911e-04 - acc: 0.9998\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 3.3457e-04 - acc: 0.9998\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 3.2094e-04 - acc: 0.9998\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 167us/sample - loss: 3.0868e-04 - acc: 0.9998\n",
      "1115/1115 [==============================] - 0s 216us/sample - loss: 0.1309 - acc: 0.9821\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 19)                135527    \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 20        \n",
      "=================================================================\n",
      "Total params: 135,547\n",
      "Trainable params: 135,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 220us/sample - loss: 0.4021 - acc: 0.9312\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 178us/sample - loss: 0.1289 - acc: 0.9807\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 179us/sample - loss: 0.0630 - acc: 0.9901\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 188us/sample - loss: 0.0387 - acc: 0.9933\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 179us/sample - loss: 0.0266 - acc: 0.9962\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 179us/sample - loss: 0.0196 - acc: 0.9962\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 176us/sample - loss: 0.0149 - acc: 0.9973\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 182us/sample - loss: 0.0118 - acc: 0.9980\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 181us/sample - loss: 0.0096 - acc: 0.9982\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 211us/sample - loss: 0.0080 - acc: 0.9984\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 206us/sample - loss: 0.0068 - acc: 0.9984\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 0.0058 - acc: 0.9987\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 0.0050 - acc: 0.9989\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 179us/sample - loss: 0.0044 - acc: 0.9991\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 193us/sample - loss: 0.0039 - acc: 0.9993\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 181us/sample - loss: 0.0034 - acc: 0.9993\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 0.0031 - acc: 0.9993\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 188us/sample - loss: 0.0028 - acc: 0.9993\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 183us/sample - loss: 0.0025 - acc: 0.9993\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 187us/sample - loss: 0.0023 - acc: 0.9993\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 186us/sample - loss: 0.0021 - acc: 0.9993\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 185us/sample - loss: 0.0019 - acc: 0.9993\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 178us/sample - loss: 0.0017 - acc: 0.9993\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 0.0016 - acc: 0.9993\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 179us/sample - loss: 0.0015 - acc: 0.9993\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 187us/sample - loss: 0.0013 - acc: 0.9993\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 176us/sample - loss: 0.0012 - acc: 0.9996\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 181us/sample - loss: 0.0011 - acc: 0.9996\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 178us/sample - loss: 0.0010 - acc: 0.9998\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 177us/sample - loss: 9.7286e-04 - acc: 0.9998\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 182us/sample - loss: 8.9723e-04 - acc: 0.9998\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 177us/sample - loss: 8.3451e-04 - acc: 0.9998\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 7.7914e-04 - acc: 0.9998\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 7.2448e-04 - acc: 0.9998\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 6.8062e-04 - acc: 0.9998\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 178us/sample - loss: 6.3800e-04 - acc: 0.9998\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 179us/sample - loss: 6.0054e-04 - acc: 0.9998\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 189us/sample - loss: 5.6860e-04 - acc: 0.9998\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 190us/sample - loss: 5.3479e-04 - acc: 0.9998\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 188us/sample - loss: 5.0467e-04 - acc: 0.9998\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 186us/sample - loss: 4.7727e-04 - acc: 0.9998\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 182us/sample - loss: 4.5231e-04 - acc: 0.9998\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 179us/sample - loss: 4.2999e-04 - acc: 0.9998\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 4.0903e-04 - acc: 0.9998\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 178us/sample - loss: 3.8999e-04 - acc: 0.9998\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 183us/sample - loss: 3.7035e-04 - acc: 0.9998\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 191us/sample - loss: 3.5470e-04 - acc: 0.9998\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 184us/sample - loss: 3.3915e-04 - acc: 0.9998\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 177us/sample - loss: 3.2426e-04 - acc: 0.9998\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 182us/sample - loss: 3.1082e-04 - acc: 0.9998\n",
      "1115/1115 [==============================] - 0s 186us/sample - loss: 0.1309 - acc: 0.9821\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 20)                142660    \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 142,681\n",
      "Trainable params: 142,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 203us/sample - loss: 0.4501 - acc: 0.9249\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 166us/sample - loss: 0.1527 - acc: 0.9814\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0736 - acc: 0.9904\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 157us/sample - loss: 0.0446 - acc: 0.9942\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 0.0306 - acc: 0.9964\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 155us/sample - loss: 0.0229 - acc: 0.9966\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 167us/sample - loss: 0.0178 - acc: 0.9971\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 165us/sample - loss: 0.0142 - acc: 0.9975\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 162us/sample - loss: 0.0115 - acc: 0.9975\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 0.0096 - acc: 0.9980\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 157us/sample - loss: 0.0080 - acc: 0.9984\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.0068 - acc: 0.9987\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 0.0059 - acc: 0.9987\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 155us/sample - loss: 0.0051 - acc: 0.9987\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 0.0045 - acc: 0.9991\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 0.0040 - acc: 0.9991\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 155us/sample - loss: 0.0036 - acc: 0.9993\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 0.0032 - acc: 0.9993\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 0.0029 - acc: 0.9993\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 157us/sample - loss: 0.0025 - acc: 0.9993\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 0.0023 - acc: 0.9993\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459/4459 [==============================] - 1s 155us/sample - loss: 0.0021 - acc: 0.9993\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 0.0020 - acc: 0.9993\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 157us/sample - loss: 0.0018 - acc: 0.9993\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 0.0017 - acc: 0.9993\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 155us/sample - loss: 0.0016 - acc: 0.9993\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 0.0014 - acc: 0.9993\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 0.0013 - acc: 0.9993\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 166us/sample - loss: 0.0012 - acc: 0.9993\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 159us/sample - loss: 0.0011 - acc: 0.9993\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 162us/sample - loss: 0.0010 - acc: 0.9996\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 162us/sample - loss: 9.7224e-04 - acc: 0.9996\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 8.9942e-04 - acc: 0.9996\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 151us/sample - loss: 8.3288e-04 - acc: 0.9998\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 7.7518e-04 - acc: 0.9998\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 7.2159e-04 - acc: 0.9998\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 6.7352e-04 - acc: 0.9998\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 6.2985e-04 - acc: 0.9998\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 157us/sample - loss: 5.9352e-04 - acc: 0.9998\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 5.5554e-04 - acc: 0.9998\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 5.2254e-04 - acc: 0.9998\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 4.9257e-04 - acc: 0.9998\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 4.6818e-04 - acc: 0.9998\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 155us/sample - loss: 4.4348e-04 - acc: 0.9998\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 4.2208e-04 - acc: 0.9998\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 4.0483e-04 - acc: 0.9998\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 154us/sample - loss: 3.8451e-04 - acc: 0.9998\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 158us/sample - loss: 3.6983e-04 - acc: 0.9998\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 155us/sample - loss: 3.5221e-04 - acc: 0.9998\n",
      "1115/1115 [==============================] - 0s 187us/sample - loss: 0.1279 - acc: 0.9830\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nresults = [0,0]\n",
    "for i in range(1,21):\n",
    "    ## Crea un modelo vacio    \n",
    "    model = keras.Sequential()\n",
    "    ## Adiciona las capas\n",
    "    model.add(keras.layers.Dense(units = i, activation=tf.nn.relu, input_dim = X_train.shape[1]))\n",
    "    model.add(keras.layers.Dense(units = 1, activation=tf.nn.sigmoid))\n",
    "    \n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc']\n",
    "                  )\n",
    "    ## Estructura del modelo creado\n",
    "    model.fit(X_train,Y_train,epochs=50,batch_size=30)\n",
    "    r = model.evaluate(X_test, Y_test)\n",
    "    if(r[1]>nresults[1]):\n",
    "        nresults = [i,r[1]]\n",
    "    model = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se elige la cantidad de capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 8)                 57064     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 57,073\n",
      "Trainable params: 57,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 193us/sample - loss: 0.4477 - acc: 0.9036\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 0.1890 - acc: 0.9679\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 0.1018 - acc: 0.9845\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 0.0644 - acc: 0.9892\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0450 - acc: 0.9924\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0334 - acc: 0.9953\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0259 - acc: 0.9962\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0206 - acc: 0.9962\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 134us/sample - loss: 0.0169 - acc: 0.9971\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0141 - acc: 0.9978\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 134us/sample - loss: 0.0120 - acc: 0.9978\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0103 - acc: 0.9980\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0090 - acc: 0.9982\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 133us/sample - loss: 0.0079 - acc: 0.9984\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0069 - acc: 0.9987\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0061 - acc: 0.9989\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0055 - acc: 0.9989\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 133us/sample - loss: 0.0049 - acc: 0.9989\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 133us/sample - loss: 0.0044 - acc: 0.9991\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 133us/sample - loss: 0.0040 - acc: 0.9993\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 132us/sample - loss: 0.0036 - acc: 0.9993\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 131us/sample - loss: 0.0033 - acc: 0.9993\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 133us/sample - loss: 0.0030 - acc: 0.9993\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 134us/sample - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0025 - acc: 0.9993\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0023 - acc: 0.9993\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 146us/sample - loss: 0.0021 - acc: 0.9993\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 0.0019 - acc: 0.9993\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 0.0018 - acc: 0.9993\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 134us/sample - loss: 0.0016 - acc: 0.9993\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 133us/sample - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0014 - acc: 0.9996\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 0.0013 - acc: 0.9996\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 0.0012 - acc: 0.9998\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 134us/sample - loss: 0.0011 - acc: 0.9998\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 131us/sample - loss: 0.0010 - acc: 0.9998\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 133us/sample - loss: 9.5830e-04 - acc: 0.9998\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 133us/sample - loss: 8.9217e-04 - acc: 0.9998\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 8.2973e-04 - acc: 0.9998\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 150us/sample - loss: 7.7391e-04 - acc: 0.9998\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 7.2468e-04 - acc: 0.9998\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 6.7896e-04 - acc: 0.9998\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 6.3608e-04 - acc: 0.9998\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 147us/sample - loss: 5.9760e-04 - acc: 0.9998\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 5.6161e-04 - acc: 0.9998\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 5.3093e-04 - acc: 0.9998\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 133us/sample - loss: 4.9895e-04 - acc: 0.9998\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 133us/sample - loss: 4.7354e-04 - acc: 0.9998\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 4.4953e-04 - acc: 0.9998\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 4.2701e-04 - acc: 0.9998\n",
      "1115/1115 [==============================] - 0s 192us/sample - loss: 0.1238 - acc: 0.9812\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 8)                 57064     \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 57,145\n",
      "Trainable params: 57,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 208us/sample - loss: 0.4569 - acc: 0.9009\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 0.1357 - acc: 0.9773\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 147us/sample - loss: 0.0555 - acc: 0.9899\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 0.0310 - acc: 0.9955\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 165us/sample - loss: 0.0200 - acc: 0.9964\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 158us/sample - loss: 0.0133 - acc: 0.9975\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 0.0094 - acc: 0.9982\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0070 - acc: 0.9989\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0054 - acc: 0.9991\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 148us/sample - loss: 0.0042 - acc: 0.9993\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0034 - acc: 0.9996\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 134us/sample - loss: 0.0028 - acc: 0.9996\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 0.0023 - acc: 0.9996\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 133us/sample - loss: 0.0019 - acc: 0.9996\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 0.0016 - acc: 0.9996\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459/4459 [==============================] - 1s 136us/sample - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 134us/sample - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 9.2287e-04 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 7.8996e-04 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 134us/sample - loss: 6.6786e-04 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 134us/sample - loss: 5.7552e-04 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 4.9558e-04 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 4.3028e-04 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 3.7600e-04 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 3.2812e-04 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 2.8880e-04 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 2.5314e-04 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 2.2376e-04 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 133us/sample - loss: 1.9691e-04 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 1.7547e-04 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 1.5543e-04 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 1.3811e-04 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 147us/sample - loss: 1.2225e-04 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 1.0912e-04 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 134us/sample - loss: 9.7596e-05 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 8.6927e-05 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 133us/sample - loss: 7.7606e-05 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 6.9236e-05 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 6.2168e-05 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 5.5313e-05 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 4.9878e-05 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 4.4696e-05 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 4.0055e-05 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 3.6225e-05 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 3.2574e-05 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 2.9423e-05 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 2.6364e-05 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 135us/sample - loss: 2.3875e-05 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 136us/sample - loss: 2.1484e-05 - acc: 1.0000s - loss: 3.1905e-05 - \n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 1.9405e-05 - acc: 1.0000\n",
      "1115/1115 [==============================] - 0s 216us/sample - loss: 0.1579 - acc: 0.9821\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 8)                 57064     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 57,217\n",
      "Trainable params: 57,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 229us/sample - loss: 0.4285 - acc: 0.8953\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 159us/sample - loss: 0.0722 - acc: 0.9850\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 164us/sample - loss: 0.0298 - acc: 0.9937\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 159us/sample - loss: 0.0164 - acc: 0.9969\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 159us/sample - loss: 0.0111 - acc: 0.9975\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0080 - acc: 0.9982\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 0.0059 - acc: 0.9987\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 0.0045 - acc: 0.9989\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 0.0033 - acc: 0.9989\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 0.0023 - acc: 0.9991\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 0.0016 - acc: 0.9996\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 0.0012 - acc: 0.9998\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 8.4253e-04 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 6.5537e-04 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 5.0049e-04 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 142us/sample - loss: 3.9674e-04 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 3.1979e-04 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 2.6068e-04 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 2.1563e-04 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 1.8083e-04 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 1.5235e-04 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 1.3030e-04 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 1.1136e-04 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 149us/sample - loss: 9.6781e-05 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 152us/sample - loss: 8.3579e-05 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 7.4596e-05 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 147us/sample - loss: 6.4461e-05 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 151us/sample - loss: 5.6663e-05 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 5.0122e-05 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 4.4212e-05 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 148us/sample - loss: 3.9300e-05 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 3.5112e-05 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 3.1383e-05 - acc: 1.0000\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459/4459 [==============================] - 1s 143us/sample - loss: 2.8002e-05 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 144us/sample - loss: 2.5139e-05 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 143us/sample - loss: 2.2632e-05 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 2.0378e-05 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 1.8337e-05 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 1.6508e-05 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 1.4899e-05 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 137us/sample - loss: 1.3466e-05 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 1.2194e-05 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 1.1007e-05 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 9.9919e-06 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 138us/sample - loss: 9.0441e-06 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 139us/sample - loss: 8.2450e-06 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 141us/sample - loss: 7.4726e-06 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 6.7895e-06 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 140us/sample - loss: 6.1828e-06 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 145us/sample - loss: 5.6197e-06 - acc: 1.0000\n",
      "1115/1115 [==============================] - 0s 211us/sample - loss: 0.1674 - acc: 0.9830\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 8)                 57064     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 57,289\n",
      "Trainable params: 57,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 229us/sample - loss: 0.4231 - acc: 0.8704\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 175us/sample - loss: 0.0922 - acc: 0.9807\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 177us/sample - loss: 0.0271 - acc: 0.9930\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 163us/sample - loss: 0.0122 - acc: 0.9969\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 164us/sample - loss: 0.0059 - acc: 0.9984\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 162us/sample - loss: 0.0037 - acc: 0.9993\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 164us/sample - loss: 0.0019 - acc: 0.9993\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 164us/sample - loss: 0.0012 - acc: 0.9996\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 161us/sample - loss: 7.2171e-04 - acc: 1.0000\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 186us/sample - loss: 5.0524e-04 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 190us/sample - loss: 3.6838e-04 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 239us/sample - loss: 2.7361e-04 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 212us/sample - loss: 2.1708e-04 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 191us/sample - loss: 1.6993e-04 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 188us/sample - loss: 1.3854e-04 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 190us/sample - loss: 1.1526e-04 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 187us/sample - loss: 9.6403e-05 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 192us/sample - loss: 8.2137e-05 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 190us/sample - loss: 7.0321e-05 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 187us/sample - loss: 6.0556e-05 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 188us/sample - loss: 5.2139e-05 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 192us/sample - loss: 4.5533e-05 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 190us/sample - loss: 3.9818e-05 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 167us/sample - loss: 3.4835e-05 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 160us/sample - loss: 3.0815e-05 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 159us/sample - loss: 2.7188e-05 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 162us/sample - loss: 2.4172e-05 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 159us/sample - loss: 2.1461e-05 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 158us/sample - loss: 1.9211e-05 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 159us/sample - loss: 1.7143e-05 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 163us/sample - loss: 1.5449e-05 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 163us/sample - loss: 1.3773e-05 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 163us/sample - loss: 1.2391e-05 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 163us/sample - loss: 1.1162e-05 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 164us/sample - loss: 1.0061e-05 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 164us/sample - loss: 9.0947e-06 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 164us/sample - loss: 8.2486e-06 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 211us/sample - loss: 7.4898e-06 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 217us/sample - loss: 6.7171e-06 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 188us/sample - loss: 6.0912e-06 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 189us/sample - loss: 5.5293e-06 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 195us/sample - loss: 5.0134e-06 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 175us/sample - loss: 4.5505e-06 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 313us/sample - loss: 4.1432e-06 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 242us/sample - loss: 3.7598e-06 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 258us/sample - loss: 3.4318e-06 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 217us/sample - loss: 3.1219e-06 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 181us/sample - loss: 2.8365e-06 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 187us/sample - loss: 2.5847e-06 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 200us/sample - loss: 2.3688e-06 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115/1115 [==============================] - 0s 222us/sample - loss: 0.2028 - acc: 0.9821\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 8)                 57064     \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 57,361\n",
      "Trainable params: 57,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 269us/sample - loss: 0.5182 - acc: 0.9137\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 186us/sample - loss: 0.1102 - acc: 0.9895\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 181us/sample - loss: 0.0260 - acc: 0.9953\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 188us/sample - loss: 0.0150 - acc: 0.9973\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 197us/sample - loss: 0.0107 - acc: 0.9980\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 202us/sample - loss: 0.0080 - acc: 0.9984\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 171us/sample - loss: 0.0066 - acc: 0.9984\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 170us/sample - loss: 0.0049 - acc: 0.9987\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 172us/sample - loss: 0.0026 - acc: 0.9991\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 170us/sample - loss: 8.4394e-04 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 191us/sample - loss: 4.4468e-04 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 202us/sample - loss: 2.9883e-04 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 181us/sample - loss: 2.2267e-04 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 220us/sample - loss: 1.7221e-04 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 218us/sample - loss: 1.3798e-04 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 1.1318e-04 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 170us/sample - loss: 9.3821e-05 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 208us/sample - loss: 7.8518e-05 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 179us/sample - loss: 6.7322e-05 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 179us/sample - loss: 5.8015e-05 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 227us/sample - loss: 5.0161e-05 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 194us/sample - loss: 4.3553e-05 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 175us/sample - loss: 3.8023e-05 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 174us/sample - loss: 3.3193e-05 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 170us/sample - loss: 2.9124e-05 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 169us/sample - loss: 2.5599e-05 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 188us/sample - loss: 2.2531e-05 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 213us/sample - loss: 1.9942e-05 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 169us/sample - loss: 1.7630e-05 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 166us/sample - loss: 1.5739e-05 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 167us/sample - loss: 1.3845e-05 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 169us/sample - loss: 1.2357e-05 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 171us/sample - loss: 1.1000e-05 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 172us/sample - loss: 9.8134e-06 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 170us/sample - loss: 8.7502e-06 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 177us/sample - loss: 7.8523e-06 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 183us/sample - loss: 7.0277e-06 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 195us/sample - loss: 6.2821e-06 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 197us/sample - loss: 5.6400e-06 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 182us/sample - loss: 5.0725e-06 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 175us/sample - loss: 4.5543e-06 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 168us/sample - loss: 4.1084e-06 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 169us/sample - loss: 3.7135e-06 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 170us/sample - loss: 3.3380e-06 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 173us/sample - loss: 3.0137e-06 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 168us/sample - loss: 2.7180e-06 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 176us/sample - loss: 2.4581e-06 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 192us/sample - loss: 2.2329e-06 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 172us/sample - loss: 2.0133e-06 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 175us/sample - loss: 1.8265e-06 - acc: 1.0000\n",
      "1115/1115 [==============================] - 0s 231us/sample - loss: 0.2241 - acc: 0.9839\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 8)                 57064     \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 57,433\n",
      "Trainable params: 57,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 255us/sample - loss: 0.4031 - acc: 0.8659\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 193us/sample - loss: 0.1157 - acc: 0.9643\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 190us/sample - loss: 0.0339 - acc: 0.9955\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459/4459 [==============================] - 1s 221us/sample - loss: 0.0111 - acc: 0.9973\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 227us/sample - loss: 0.0048 - acc: 0.9987\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 202us/sample - loss: 0.0026 - acc: 0.9991\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 205us/sample - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 236us/sample - loss: 8.7458e-04 - acc: 1.0000\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 212us/sample - loss: 5.5652e-04 - acc: 1.0000\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 181us/sample - loss: 3.9327e-04 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 175us/sample - loss: 2.8796e-04 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 172us/sample - loss: 2.1152e-04 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 173us/sample - loss: 1.6020e-04 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 176us/sample - loss: 1.2560e-04 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 173us/sample - loss: 1.0065e-04 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 172us/sample - loss: 8.0811e-05 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 173us/sample - loss: 6.6660e-05 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 209us/sample - loss: 5.5421e-05 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 4.6641e-05 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 3.9998e-05 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 174us/sample - loss: 3.4282e-05 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 171us/sample - loss: 2.9488e-05 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 173us/sample - loss: 2.5785e-05 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 170us/sample - loss: 2.2778e-05 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 173us/sample - loss: 2.0171e-05 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 182us/sample - loss: 1.7879e-05 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 194us/sample - loss: 1.5965e-05 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 177us/sample - loss: 1.4248e-05 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 174us/sample - loss: 1.2765e-05 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 175us/sample - loss: 1.1453e-05 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 171us/sample - loss: 1.0304e-05 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 172us/sample - loss: 9.2699e-06 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 172us/sample - loss: 8.3306e-06 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 173us/sample - loss: 7.5028e-06 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 173us/sample - loss: 6.7808e-06 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 172us/sample - loss: 6.1182e-06 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 174us/sample - loss: 5.5465e-06 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 172us/sample - loss: 5.0049e-06 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 172us/sample - loss: 4.5404e-06 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 171us/sample - loss: 4.1216e-06 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 176us/sample - loss: 3.7335e-06 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 172us/sample - loss: 3.3984e-06 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 170us/sample - loss: 3.0922e-06 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 2.8106e-06 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 175us/sample - loss: 2.5548e-06 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 175us/sample - loss: 2.3281e-06 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 184us/sample - loss: 2.1205e-06 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 174us/sample - loss: 1.9376e-06 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 204us/sample - loss: 1.7663e-06 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 199us/sample - loss: 1.6169e-06 - acc: 1.0000\n",
      "1115/1115 [==============================] - 0s 242us/sample - loss: 0.1951 - acc: 0.9839\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 8)                 57064     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 57,505\n",
      "Trainable params: 57,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 268us/sample - loss: 0.3991 - acc: 0.8661\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 171us/sample - loss: 0.1430 - acc: 0.9215\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 168us/sample - loss: 0.0594 - acc: 0.9922\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 173us/sample - loss: 0.0100 - acc: 0.9978\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 171us/sample - loss: 0.0059 - acc: 0.9982\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 169us/sample - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 170us/sample - loss: 0.0013 - acc: 0.9996\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 174us/sample - loss: 5.9310e-04 - acc: 0.9998\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 164us/sample - loss: 2.1331e-04 - acc: 1.0000\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 172us/sample - loss: 1.5343e-04 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 175us/sample - loss: 1.1709e-04 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 183us/sample - loss: 9.2430e-05 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 172us/sample - loss: 7.3648e-05 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 171us/sample - loss: 6.0168e-05 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 171us/sample - loss: 4.9697e-05 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - ETA: 0s - loss: 4.3159e-05 - acc: 1.000 - 1s 175us/sample - loss: 4.2061e-05 - acc: 1.0000\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459/4459 [==============================] - 1s 173us/sample - loss: 3.5454e-05 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 172us/sample - loss: 3.0449e-05 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 176us/sample - loss: 2.6235e-05 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 2.2785e-05 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 1.9844e-05 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 182us/sample - loss: 1.7401e-05 - acc: 1.0000s - loss: 1.1587e-0\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 175us/sample - loss: 1.5319e-05 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 172us/sample - loss: 1.3488e-05 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 169us/sample - loss: 1.1995e-05 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 168us/sample - loss: 1.0728e-05 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 184us/sample - loss: 9.5450e-06 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 170us/sample - loss: 8.5643e-06 - acc: 1.0000\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 178us/sample - loss: 7.7031e-06 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 171us/sample - loss: 6.9042e-06 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 160us/sample - loss: 6.2060e-06 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 5.6057e-06 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 158us/sample - loss: 5.0663e-06 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 159us/sample - loss: 4.5712e-06 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 4.1551e-06 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 159us/sample - loss: 3.7596e-06 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 3.4187e-06 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 166us/sample - loss: 3.1082e-06 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 176us/sample - loss: 2.8224e-06 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 184us/sample - loss: 2.5678e-06 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 172us/sample - loss: 2.3346e-06 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 156us/sample - loss: 2.1313e-06 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 1.9354e-06 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 157us/sample - loss: 1.7686e-06 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 153us/sample - loss: 1.6130e-06 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 157us/sample - loss: 1.4741e-06 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 157us/sample - loss: 1.3438e-06 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 155us/sample - loss: 1.2303e-06 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 155us/sample - loss: 1.1230e-06 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 155us/sample - loss: 1.0251e-06 - acc: 1.0000\n",
      "1115/1115 [==============================] - 0s 259us/sample - loss: 0.2053 - acc: 0.9848\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_75 (Dense)             (None, 8)                 57064     \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 57,577\n",
      "Trainable params: 57,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 271us/sample - loss: 0.4808 - acc: 0.8619\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 197us/sample - loss: 0.1217 - acc: 0.9502\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 196us/sample - loss: 0.0305 - acc: 0.9928\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 188us/sample - loss: 0.0156 - acc: 0.9960\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 178us/sample - loss: 0.0079 - acc: 0.9982\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 175us/sample - loss: 0.0035 - acc: 0.9993\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 176us/sample - loss: 0.0018 - acc: 0.9996\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 176us/sample - loss: 6.3426e-04 - acc: 1.0000\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 182us/sample - loss: 2.3760e-04 - acc: 1.0000\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 181us/sample - loss: 1.6269e-04 - acc: 1.0000\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 179us/sample - loss: 1.1965e-04 - acc: 1.0000\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 9.1187e-05 - acc: 1.0000\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 7.1606e-05 - acc: 1.0000\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 176us/sample - loss: 5.7684e-05 - acc: 1.0000\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 179us/sample - loss: 4.7557e-05 - acc: 1.0000\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 177us/sample - loss: 3.9703e-05 - acc: 1.0000\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 3.3285e-05 - acc: 1.0000\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 179us/sample - loss: 2.8299e-05 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 2.4257e-05 - acc: 1.0000\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 177us/sample - loss: 2.0938e-05 - acc: 1.0000\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 181us/sample - loss: 1.8206e-05 - acc: 1.0000\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 177us/sample - loss: 1.5909e-05 - acc: 1.0000\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 178us/sample - loss: 1.3898e-05 - acc: 1.0000\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 179us/sample - loss: 1.2258e-05 - acc: 1.0000\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 178us/sample - loss: 1.0816e-05 - acc: 1.0000\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 178us/sample - loss: 9.5552e-06 - acc: 1.0000\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 181us/sample - loss: 8.4972e-06 - acc: 1.0000\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 178us/sample - loss: 7.5760e-06 - acc: 1.0000\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459/4459 [==============================] - 1s 177us/sample - loss: 6.7715e-06 - acc: 1.0000\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 175us/sample - loss: 6.0624e-06 - acc: 1.0000\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 179us/sample - loss: 5.4326e-06 - acc: 1.0000\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 176us/sample - loss: 4.8730e-06 - acc: 1.0000\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 179us/sample - loss: 4.3713e-06 - acc: 1.0000\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 175us/sample - loss: 3.9467e-06 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 177us/sample - loss: 3.5633e-06 - acc: 1.0000\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 176us/sample - loss: 3.2184e-06 - acc: 1.0000\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 175us/sample - loss: 2.9042e-06 - acc: 1.0000\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 175us/sample - loss: 2.6241e-06 - acc: 1.0000\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 179us/sample - loss: 2.3817e-06 - acc: 1.0000\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 177us/sample - loss: 2.1621e-06 - acc: 1.0000\n",
      "Epoch 41/50\n",
      "4459/4459 [==============================] - 1s 178us/sample - loss: 1.9583e-06 - acc: 1.0000\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 1.7800e-06 - acc: 1.0000\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 179us/sample - loss: 1.6177e-06 - acc: 1.0000\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 175us/sample - loss: 1.4674e-06 - acc: 1.0000\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 177us/sample - loss: 1.3351e-06 - acc: 1.0000\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 176us/sample - loss: 1.2150e-06 - acc: 1.0000\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 177us/sample - loss: 1.1097e-06 - acc: 1.0000\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - 1s 175us/sample - loss: 1.0096e-06 - acc: 1.0000\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 179us/sample - loss: 9.1902e-07 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 177us/sample - loss: 8.3573e-07 - acc: 1.0000\n",
      "1115/1115 [==============================] - 0s 278us/sample - loss: 0.2147 - acc: 0.9848\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_84 (Dense)             (None, 8)                 57064     \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 57,649\n",
      "Trainable params: 57,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "4459/4459 [==============================] - 1s 283us/sample - loss: 0.3638 - acc: 0.8661\n",
      "Epoch 2/50\n",
      "4459/4459 [==============================] - 1s 207us/sample - loss: 0.1280 - acc: 0.9500\n",
      "Epoch 3/50\n",
      "4459/4459 [==============================] - 1s 204us/sample - loss: 0.0885 - acc: 0.9942\n",
      "Epoch 4/50\n",
      "4459/4459 [==============================] - 1s 188us/sample - loss: 0.0616 - acc: 0.9978\n",
      "Epoch 5/50\n",
      "4459/4459 [==============================] - 1s 187us/sample - loss: 0.0387 - acc: 0.9982\n",
      "Epoch 6/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 0.0207 - acc: 0.9987\n",
      "Epoch 7/50\n",
      "4459/4459 [==============================] - 1s 187us/sample - loss: 0.0104 - acc: 0.9989\n",
      "Epoch 8/50\n",
      "4459/4459 [==============================] - 1s 189us/sample - loss: 0.0064 - acc: 0.9993\n",
      "Epoch 9/50\n",
      "4459/4459 [==============================] - 1s 188us/sample - loss: 0.0047 - acc: 0.9996\n",
      "Epoch 10/50\n",
      "4459/4459 [==============================] - 1s 184us/sample - loss: 0.0050 - acc: 0.9993\n",
      "Epoch 11/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 0.0036 - acc: 0.9996\n",
      "Epoch 12/50\n",
      "4459/4459 [==============================] - 1s 183us/sample - loss: 0.0033 - acc: 0.9996\n",
      "Epoch 13/50\n",
      "4459/4459 [==============================] - 1s 181us/sample - loss: 0.0032 - acc: 0.9996\n",
      "Epoch 14/50\n",
      "4459/4459 [==============================] - 1s 184us/sample - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 15/50\n",
      "4459/4459 [==============================] - 1s 181us/sample - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 16/50\n",
      "4459/4459 [==============================] - 1s 182us/sample - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 17/50\n",
      "4459/4459 [==============================] - 1s 185us/sample - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 18/50\n",
      "4459/4459 [==============================] - 1s 187us/sample - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 19/50\n",
      "4459/4459 [==============================] - 1s 184us/sample - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 20/50\n",
      "4459/4459 [==============================] - 1s 183us/sample - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 21/50\n",
      "4459/4459 [==============================] - 1s 184us/sample - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 22/50\n",
      "4459/4459 [==============================] - 1s 186us/sample - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 23/50\n",
      "4459/4459 [==============================] - 1s 197us/sample - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 24/50\n",
      "4459/4459 [==============================] - 1s 194us/sample - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 25/50\n",
      "4459/4459 [==============================] - 1s 200us/sample - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 26/50\n",
      "4459/4459 [==============================] - 1s 191us/sample - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 27/50\n",
      "4459/4459 [==============================] - 1s 182us/sample - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 28/50\n",
      "4459/4459 [==============================] - 1s 185us/sample - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 29/50\n",
      "4459/4459 [==============================] - 1s 183us/sample - loss: 0.0035 - acc: 0.9996\n",
      "Epoch 30/50\n",
      "4459/4459 [==============================] - 1s 186us/sample - loss: 0.0063 - acc: 0.9989\n",
      "Epoch 31/50\n",
      "4459/4459 [==============================] - 1s 186us/sample - loss: 0.0112 - acc: 0.9971\n",
      "Epoch 32/50\n",
      "4459/4459 [==============================] - 1s 184us/sample - loss: 0.0161 - acc: 0.9964\n",
      "Epoch 33/50\n",
      "4459/4459 [==============================] - 1s 184us/sample - loss: 0.0048 - acc: 0.9989\n",
      "Epoch 34/50\n",
      "4459/4459 [==============================] - 1s 182us/sample - loss: 0.0033 - acc: 0.9996\n",
      "Epoch 35/50\n",
      "4459/4459 [==============================] - 1s 185us/sample - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 36/50\n",
      "4459/4459 [==============================] - 1s 181us/sample - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 37/50\n",
      "4459/4459 [==============================] - 1s 184us/sample - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 38/50\n",
      "4459/4459 [==============================] - 1s 184us/sample - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 39/50\n",
      "4459/4459 [==============================] - 1s 184us/sample - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 40/50\n",
      "4459/4459 [==============================] - 1s 188us/sample - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459/4459 [==============================] - 1s 180us/sample - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 42/50\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 43/50\n",
      "4459/4459 [==============================] - 1s 187us/sample - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 44/50\n",
      "4459/4459 [==============================] - 1s 183us/sample - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 45/50\n",
      "4459/4459 [==============================] - 1s 182us/sample - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 46/50\n",
      "4459/4459 [==============================] - 1s 185us/sample - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 47/50\n",
      "4459/4459 [==============================] - 1s 182us/sample - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 48/50\n",
      "4459/4459 [==============================] - ETA: 0s - loss: 0.0031 - acc: 0.999 - 1s 184us/sample - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 49/50\n",
      "4459/4459 [==============================] - 1s 182us/sample - loss: 0.0032 - acc: 0.9996\n",
      "Epoch 50/50\n",
      "4459/4459 [==============================] - 1s 181us/sample - loss: 0.0019 - acc: 0.9998\n",
      "1115/1115 [==============================] - 0s 279us/sample - loss: 0.1910 - acc: 0.9830\n"
     ]
    }
   ],
   "source": [
    "cresults = [0,0]\n",
    "for i in range(1,10):\n",
    "    ## Crea un modelo vacio    \n",
    "    model = keras.Sequential()\n",
    "    ## Adiciona las capas\n",
    "    for j in range(0,i):\n",
    "        model.add(keras.layers.Dense(units =nresults[0], activation=tf.nn.relu, input_dim = X_train.shape[1]))\n",
    "    model.add(keras.layers.Dense(units = 1, activation=tf.nn.sigmoid))\n",
    "    \n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc']\n",
    "                  )\n",
    "    ## Estructura del modelo creado\n",
    "    model.fit(X_train,Y_train,epochs=50,batch_size=30)\n",
    "    r = model.evaluate(X_test, Y_test)\n",
    "    if(r[1]>cresults[1]):\n",
    "        cresults = [i,r[1]]\n",
    "    model = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidades óptimas de neuronas y capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuronas ----  [8, 0.9829596]\n",
      "Capas ----  [7, 0.9847534]\n"
     ]
    }
   ],
   "source": [
    "print(\"Neuronas ---- \" ,nresults)\n",
    "print(\"Capas ---- \" ,cresults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo definitivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_94 (Dense)             (None, 8)                 57064     \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 57,505\n",
      "Trainable params: 57,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "4459/4459 [==============================] - 1s 286us/sample - loss: 0.4020 - acc: 0.9033 - mean_squared_error: 0.1281\n",
      "Epoch 2/100\n",
      "4459/4459 [==============================] - 1s 213us/sample - loss: 0.0501 - acc: 0.9877 - mean_squared_error: 0.0106\n",
      "Epoch 3/100\n",
      "4459/4459 [==============================] - 1s 210us/sample - loss: 0.0205 - acc: 0.9957 - mean_squared_error: 0.0039\n",
      "Epoch 4/100\n",
      "4459/4459 [==============================] - 1s 207us/sample - loss: 0.0104 - acc: 0.9980 - mean_squared_error: 0.0019\n",
      "Epoch 5/100\n",
      "4459/4459 [==============================] - 1s 203us/sample - loss: 0.0055 - acc: 0.9982 - mean_squared_error: 0.0013\n",
      "Epoch 6/100\n",
      "4459/4459 [==============================] - 1s 193us/sample - loss: 0.0017 - acc: 0.9998 - mean_squared_error: 2.5235e-04\n",
      "Epoch 7/100\n",
      "4459/4459 [==============================] - 1s 193us/sample - loss: 7.2297e-04 - acc: 0.9998 - mean_squared_error: 1.0358e-04\n",
      "Epoch 8/100\n",
      "4459/4459 [==============================] - 1s 193us/sample - loss: 3.2465e-04 - acc: 1.0000 - mean_squared_error: 8.3932e-06\n",
      "Epoch 9/100\n",
      "4459/4459 [==============================] - 1s 188us/sample - loss: 2.0434e-04 - acc: 1.0000 - mean_squared_error: 3.8614e-06\n",
      "Epoch 10/100\n",
      "4459/4459 [==============================] - 1s 185us/sample - loss: 1.4580e-04 - acc: 1.0000 - mean_squared_error: 1.8855e-06\n",
      "Epoch 11/100\n",
      "4459/4459 [==============================] - 1s 186us/sample - loss: 1.1101e-04 - acc: 1.0000 - mean_squared_error: 1.2287e-06\n",
      "Epoch 12/100\n",
      "4459/4459 [==============================] - 1s 188us/sample - loss: 8.6106e-05 - acc: 1.0000 - mean_squared_error: 5.9054e-07\n",
      "Epoch 13/100\n",
      "4459/4459 [==============================] - 1s 195us/sample - loss: 6.8821e-05 - acc: 1.0000 - mean_squared_error: 3.2269e-07\n",
      "Epoch 14/100\n",
      "4459/4459 [==============================] - 1s 197us/sample - loss: 5.6548e-05 - acc: 1.0000 - mean_squared_error: 2.2527e-07\n",
      "Epoch 15/100\n",
      "4459/4459 [==============================] - 1s 189us/sample - loss: 4.6456e-05 - acc: 1.0000 - mean_squared_error: 1.5406e-07\n",
      "Epoch 16/100\n",
      "4459/4459 [==============================] - 1s 189us/sample - loss: 3.9235e-05 - acc: 1.0000 - mean_squared_error: 1.0772e-07\n",
      "Epoch 17/100\n",
      "4459/4459 [==============================] - 1s 188us/sample - loss: 3.2903e-05 - acc: 1.0000 - mean_squared_error: 6.6605e-08\n",
      "Epoch 18/100\n",
      "4459/4459 [==============================] - 1s 189us/sample - loss: 2.8094e-05 - acc: 1.0000 - mean_squared_error: 4.7930e-08\n",
      "Epoch 19/100\n",
      "4459/4459 [==============================] - 1s 191us/sample - loss: 2.4245e-05 - acc: 1.0000 - mean_squared_error: 3.9911e-08\n",
      "Epoch 20/100\n",
      "4459/4459 [==============================] - 1s 187us/sample - loss: 2.1030e-05 - acc: 1.0000 - mean_squared_error: 2.8094e-08\n",
      "Epoch 21/100\n",
      "4459/4459 [==============================] - 1s 191us/sample - loss: 1.8230e-05 - acc: 1.0000 - mean_squared_error: 2.0198e-08\n",
      "Epoch 22/100\n",
      "4459/4459 [==============================] - 1s 189us/sample - loss: 1.6009e-05 - acc: 1.0000 - mean_squared_error: 1.6470e-08\n",
      "Epoch 23/100\n",
      "4459/4459 [==============================] - 1s 188us/sample - loss: 1.4045e-05 - acc: 1.0000 - mean_squared_error: 1.1854e-08\n",
      "Epoch 24/100\n",
      "4459/4459 [==============================] - 1s 190us/sample - loss: 1.2383e-05 - acc: 1.0000 - mean_squared_error: 9.0634e-09\n",
      "Epoch 25/100\n",
      "4459/4459 [==============================] - 1s 189us/sample - loss: 1.1021e-05 - acc: 1.0000 - mean_squared_error: 8.0098e-09\n",
      "Epoch 26/100\n",
      "4459/4459 [==============================] - 1s 196us/sample - loss: 9.7774e-06 - acc: 1.0000 - mean_squared_error: 6.1914e-09\n",
      "Epoch 27/100\n",
      "4459/4459 [==============================] - 1s 187us/sample - loss: 8.6828e-06 - acc: 1.0000 - mean_squared_error: 4.8627e-09\n",
      "Epoch 28/100\n",
      "4459/4459 [==============================] - 1s 189us/sample - loss: 7.7610e-06 - acc: 1.0000 - mean_squared_error: 3.7020e-09\n",
      "Epoch 29/100\n",
      "4459/4459 [==============================] - 1s 191us/sample - loss: 6.9392e-06 - acc: 1.0000 - mean_squared_error: 3.0445e-09\n",
      "Epoch 30/100\n",
      "4459/4459 [==============================] - 1s 189us/sample - loss: 6.2058e-06 - acc: 1.0000 - mean_squared_error: 2.3827e-09\n",
      "Epoch 31/100\n",
      "4459/4459 [==============================] - 1s 188us/sample - loss: 5.5867e-06 - acc: 1.0000 - mean_squared_error: 1.8769e-09\n",
      "Epoch 32/100\n",
      "4459/4459 [==============================] - 1s 188us/sample - loss: 5.0164e-06 - acc: 1.0000 - mean_squared_error: 1.6360e-09\n",
      "Epoch 33/100\n",
      "4459/4459 [==============================] - 1s 188us/sample - loss: 4.5187e-06 - acc: 1.0000 - mean_squared_error: 1.2990e-09\n",
      "Epoch 34/100\n",
      "4459/4459 [==============================] - 1s 187us/sample - loss: 4.0754e-06 - acc: 1.0000 - mean_squared_error: 1.0597e-09\n",
      "Epoch 35/100\n",
      "4459/4459 [==============================] - 1s 189us/sample - loss: 3.6746e-06 - acc: 1.0000 - mean_squared_error: 8.1435e-10\n",
      "Epoch 36/100\n",
      "4459/4459 [==============================] - 1s 189us/sample - loss: 3.3194e-06 - acc: 1.0000 - mean_squared_error: 7.0161e-10\n",
      "Epoch 37/100\n",
      "4459/4459 [==============================] - 1s 187us/sample - loss: 3.0058e-06 - acc: 1.0000 - mean_squared_error: 5.5732e-10\n",
      "Epoch 38/100\n",
      "4459/4459 [==============================] - 1s 191us/sample - loss: 2.7263e-06 - acc: 1.0000 - mean_squared_error: 4.4591e-10\n",
      "Epoch 39/100\n",
      "4459/4459 [==============================] - 1s 189us/sample - loss: 2.4723e-06 - acc: 1.0000 - mean_squared_error: 3.8665e-10\n",
      "Epoch 40/100\n",
      "4459/4459 [==============================] - 1s 190us/sample - loss: 2.2535e-06 - acc: 1.0000 - mean_squared_error: 3.3651e-10\n",
      "Epoch 41/100\n",
      "4459/4459 [==============================] - 1s 192us/sample - loss: 2.0358e-06 - acc: 1.0000 - mean_squared_error: 2.5428e-10\n",
      "Epoch 42/100\n",
      "4459/4459 [==============================] - 1s 187us/sample - loss: 1.8524e-06 - acc: 1.0000 - mean_squared_error: 2.1490e-10\n",
      "Epoch 43/100\n",
      "4459/4459 [==============================] - 1s 190us/sample - loss: 1.6807e-06 - acc: 1.0000 - mean_squared_error: 1.7495e-10\n",
      "Epoch 44/100\n",
      "4459/4459 [==============================] - 1s 187us/sample - loss: 1.5306e-06 - acc: 1.0000 - mean_squared_error: 1.4618e-10\n",
      "Epoch 45/100\n",
      "4459/4459 [==============================] - 1s 186us/sample - loss: 1.3920e-06 - acc: 1.0000 - mean_squared_error: 1.2304e-10\n",
      "Epoch 46/100\n",
      "4459/4459 [==============================] - 1s 187us/sample - loss: 1.2688e-06 - acc: 1.0000 - mean_squared_error: 1.0365e-10\n",
      "Epoch 47/100\n",
      "4459/4459 [==============================] - 1s 185us/sample - loss: 1.1609e-06 - acc: 1.0000 - mean_squared_error: 8.9502e-11\n",
      "Epoch 48/100\n",
      "4459/4459 [==============================] - 1s 188us/sample - loss: 1.0563e-06 - acc: 1.0000 - mean_squared_error: 7.0238e-11\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4459/4459 [==============================] - 1s 179us/sample - loss: 9.6596e-07 - acc: 1.0000 - mean_squared_error: 5.9750e-11\n",
      "Epoch 50/100\n",
      "4459/4459 [==============================] - 1s 179us/sample - loss: 8.8016e-07 - acc: 1.0000 - mean_squared_error: 5.2413e-11\n",
      "Epoch 51/100\n",
      "4459/4459 [==============================] - 1s 176us/sample - loss: 8.0213e-07 - acc: 1.0000 - mean_squared_error: 4.1911e-11\n",
      "Epoch 52/100\n",
      "4459/4459 [==============================] - 1s 180us/sample - loss: 7.3235e-07 - acc: 1.0000 - mean_squared_error: 3.4699e-11\n",
      "Epoch 53/100\n",
      "4459/4459 [==============================] - 1s 178us/sample - loss: 6.6980e-07 - acc: 1.0000 - mean_squared_error: 3.0965e-11\n",
      "Epoch 54/100\n",
      "4459/4459 [==============================] - 1s 177us/sample - loss: 6.1344e-07 - acc: 1.0000 - mean_squared_error: 2.4957e-11\n",
      "Epoch 55/100\n",
      "4459/4459 [==============================] - 1s 179us/sample - loss: 5.6011e-07 - acc: 1.0000 - mean_squared_error: 2.1644e-11\n",
      "Epoch 56/100\n",
      "4459/4459 [==============================] - 1s 178us/sample - loss: 5.1192e-07 - acc: 1.0000 - mean_squared_error: 1.7971e-11\n",
      "Epoch 57/100\n",
      "4459/4459 [==============================] - 1s 194us/sample - loss: 4.6863e-07 - acc: 1.0000 - mean_squared_error: 1.4791e-11\n",
      "Epoch 58/100\n",
      "4459/4459 [==============================] - 1s 198us/sample - loss: 4.2976e-07 - acc: 1.0000 - mean_squared_error: 1.2816e-11\n",
      "Epoch 59/100\n",
      "4459/4459 [==============================] - 1s 201us/sample - loss: 3.9326e-07 - acc: 1.0000 - mean_squared_error: 1.0694e-11\n",
      "Epoch 60/100\n",
      "4459/4459 [==============================] - 1s 199us/sample - loss: 3.6036e-07 - acc: 1.0000 - mean_squared_error: 9.2947e-12\n",
      "Epoch 61/100\n",
      "4459/4459 [==============================] - 1s 198us/sample - loss: 3.2868e-07 - acc: 1.0000 - mean_squared_error: 7.3089e-12\n",
      "Epoch 62/100\n",
      "4459/4459 [==============================] - 1s 200us/sample - loss: 3.0142e-07 - acc: 1.0000 - mean_squared_error: 6.3933e-12\n",
      "Epoch 63/100\n",
      "4459/4459 [==============================] - 1s 245us/sample - loss: 2.7728e-07 - acc: 1.0000 - mean_squared_error: 5.3384e-12\n",
      "Epoch 64/100\n",
      "4459/4459 [==============================] - 1s 226us/sample - loss: 2.5301e-07 - acc: 1.0000 - mean_squared_error: 4.3371e-12\n",
      "Epoch 65/100\n",
      "4459/4459 [==============================] - 1s 185us/sample - loss: 2.3218e-07 - acc: 1.0000 - mean_squared_error: 3.8025e-12\n",
      "Epoch 66/100\n",
      "4459/4459 [==============================] - 1s 185us/sample - loss: 2.1400e-07 - acc: 1.0000 - mean_squared_error: 3.2546e-12\n",
      "Epoch 67/100\n",
      "4459/4459 [==============================] - 1s 188us/sample - loss: 1.9525e-07 - acc: 1.0000 - mean_squared_error: 2.7351e-12\n",
      "Epoch 68/100\n",
      "4459/4459 [==============================] - 1s 187us/sample - loss: 1.7899e-07 - acc: 1.0000 - mean_squared_error: 2.2616e-12\n",
      "Epoch 69/100\n",
      "4459/4459 [==============================] - 1s 186us/sample - loss: 1.6472e-07 - acc: 1.0000 - mean_squared_error: 2.0037e-12\n",
      "Epoch 70/100\n",
      "4459/4459 [==============================] - 1s 184us/sample - loss: 1.5107e-07 - acc: 1.0000 - mean_squared_error: 1.5934e-12\n",
      "Epoch 71/100\n",
      "4459/4459 [==============================] - 1s 200us/sample - loss: 1.3849e-07 - acc: 1.0000 - mean_squared_error: 1.3233e-12\n",
      "Epoch 72/100\n",
      "4459/4459 [==============================] - 1s 227us/sample - loss: 1.2729e-07 - acc: 1.0000 - mean_squared_error: 1.1439e-12\n",
      "Epoch 73/100\n",
      "4459/4459 [==============================] - 1s 224us/sample - loss: 1.1712e-07 - acc: 1.0000 - mean_squared_error: 9.8174e-13\n",
      "Epoch 74/100\n",
      "4459/4459 [==============================] - 1s 221us/sample - loss: 1.0743e-07 - acc: 1.0000 - mean_squared_error: 8.3628e-13\n",
      "Epoch 75/100\n",
      "4459/4459 [==============================] - 1s 224us/sample - loss: 9.8771e-08 - acc: 1.0000 - mean_squared_error: 6.9655e-13\n",
      "Epoch 76/100\n",
      "4459/4459 [==============================] - 1s 215us/sample - loss: 9.0531e-08 - acc: 1.0000 - mean_squared_error: 5.9367e-13\n",
      "Epoch 77/100\n",
      "4459/4459 [==============================] - 1s 214us/sample - loss: 8.3261e-08 - acc: 1.0000 - mean_squared_error: 4.8725e-13\n",
      "Epoch 78/100\n",
      "4459/4459 [==============================] - 1s 217us/sample - loss: 7.6604e-08 - acc: 1.0000 - mean_squared_error: 4.2552e-13\n",
      "Epoch 79/100\n",
      "4459/4459 [==============================] - 1s 218us/sample - loss: 7.0349e-08 - acc: 1.0000 - mean_squared_error: 3.5573e-13\n",
      "Epoch 80/100\n",
      "4459/4459 [==============================] - 1s 216us/sample - loss: 6.4678e-08 - acc: 1.0000 - mean_squared_error: 3.0347e-13\n",
      "Epoch 81/100\n",
      "4459/4459 [==============================] - 1s 230us/sample - loss: 5.9763e-08 - acc: 1.0000 - mean_squared_error: 2.5816e-13\n",
      "Epoch 82/100\n",
      "4459/4459 [==============================] - 1s 221us/sample - loss: 5.4696e-08 - acc: 1.0000 - mean_squared_error: 2.1213e-13\n",
      "Epoch 83/100\n",
      "4459/4459 [==============================] - 1s 216us/sample - loss: 5.0380e-08 - acc: 1.0000 - mean_squared_error: 1.7858e-13\n",
      "Epoch 84/100\n",
      "4459/4459 [==============================] - 1s 219us/sample - loss: 4.6307e-08 - acc: 1.0000 - mean_squared_error: 1.5550e-13\n",
      "Epoch 85/100\n",
      "4459/4459 [==============================] - 1s 191us/sample - loss: 4.2599e-08 - acc: 1.0000 - mean_squared_error: 1.2715e-13\n",
      "Epoch 86/100\n",
      "4459/4459 [==============================] - 1s 184us/sample - loss: 3.9380e-08 - acc: 1.0000 - mean_squared_error: 1.0845e-13\n",
      "Epoch 87/100\n",
      "4459/4459 [==============================] - 1s 184us/sample - loss: 3.6253e-08 - acc: 1.0000 - mean_squared_error: 9.4196e-14\n",
      "Epoch 88/100\n",
      "4459/4459 [==============================] - 1s 186us/sample - loss: 3.3451e-08 - acc: 1.0000 - mean_squared_error: 7.9411e-14\n",
      "Epoch 89/100\n",
      "4459/4459 [==============================] - 1s 186us/sample - loss: 3.0845e-08 - acc: 1.0000 - mean_squared_error: 6.8263e-14\n",
      "Epoch 90/100\n",
      "4459/4459 [==============================] - 1s 182us/sample - loss: 2.8565e-08 - acc: 1.0000 - mean_squared_error: 5.8167e-14\n",
      "Epoch 91/100\n",
      "4459/4459 [==============================] - 1s 182us/sample - loss: 2.6347e-08 - acc: 1.0000 - mean_squared_error: 4.9448e-14\n",
      "Epoch 92/100\n",
      "4459/4459 [==============================] - 1s 186us/sample - loss: 2.4326e-08 - acc: 1.0000 - mean_squared_error: 4.0828e-14\n",
      "Epoch 93/100\n",
      "4459/4459 [==============================] - 1s 204us/sample - loss: 2.2413e-08 - acc: 1.0000 - mean_squared_error: 3.4346e-14\n",
      "Epoch 94/100\n",
      "4459/4459 [==============================] - 1s 198us/sample - loss: 2.0725e-08 - acc: 1.0000 - mean_squared_error: 2.8239e-14\n",
      "Epoch 95/100\n",
      "4459/4459 [==============================] - 1s 183us/sample - loss: 1.9118e-08 - acc: 1.0000 - mean_squared_error: 2.5608e-14\n",
      "Epoch 96/100\n",
      "4459/4459 [==============================] - 1s 186us/sample - loss: 1.7649e-08 - acc: 1.0000 - mean_squared_error: 2.1487e-14\n",
      "Epoch 97/100\n",
      "4459/4459 [==============================] - 1s 183us/sample - loss: 1.6329e-08 - acc: 1.0000 - mean_squared_error: 1.7905e-14\n",
      "Epoch 98/100\n",
      "4459/4459 [==============================] - 1s 185us/sample - loss: 1.5089e-08 - acc: 1.0000 - mean_squared_error: 1.5388e-14\n",
      "Epoch 99/100\n",
      "4459/4459 [==============================] - 1s 182us/sample - loss: 1.3974e-08 - acc: 1.0000 - mean_squared_error: 1.3502e-14\n",
      "Epoch 100/100\n",
      "4459/4459 [==============================] - 1s 186us/sample - loss: 1.2920e-08 - acc: 1.0000 - mean_squared_error: 1.1333e-14\n",
      "1115/1115 [==============================] - 0s 300us/sample - loss: 0.2610 - acc: 0.9830 - mean_squared_error: 0.0162\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "## Adiciona las capas\n",
    "for j in range(0,cresults[0]):\n",
    "    model.add(keras.layers.Dense(units =nresults[0], activation=tf.nn.relu, input_dim = X_train.shape[1]))\n",
    "model.add(keras.layers.Dense(units = 1, activation=tf.nn.sigmoid))\n",
    "    \n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc','mse']\n",
    "              )\n",
    "## Estructura del modelo creado\n",
    "model.fit(X_train,Y_train,epochs=100,batch_size=30)\n",
    "r = model.evaluate(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo definitivo  0.9829596\n",
      "MSE del modelo definitivo  0.016154205\n"
     ]
    }
   ],
   "source": [
    "print(\"Precisión del modelo definitivo \", r[1])\n",
    "print(\"MSE del modelo definitivo \", r[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_102 (Dense)            (None, 8)                 57064     \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 57,505\n",
      "Trainable params: 57,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "3344/3344 [==============================] - 1s 310us/sample - loss: 0.4904 - acc: 0.8657 - mean_squared_error: 0.1619\n",
      "Epoch 2/100\n",
      "3344/3344 [==============================] - 1s 199us/sample - loss: 0.1662 - acc: 0.8657 - mean_squared_error: 0.0542\n",
      "Epoch 3/100\n",
      "3344/3344 [==============================] - 1s 200us/sample - loss: 0.1145 - acc: 0.8774 - mean_squared_error: 0.0384\n",
      "Epoch 4/100\n",
      "3344/3344 [==============================] - 1s 201us/sample - loss: 0.1014 - acc: 0.9961 - mean_squared_error: 0.0343\n",
      "Epoch 5/100\n",
      "3344/3344 [==============================] - 1s 200us/sample - loss: 0.0941 - acc: 0.9970 - mean_squared_error: 0.0321\n",
      "Epoch 6/100\n",
      "3344/3344 [==============================] - 1s 201us/sample - loss: 0.0872 - acc: 0.9982 - mean_squared_error: 0.0297\n",
      "Epoch 7/100\n",
      "3344/3344 [==============================] - 1s 202us/sample - loss: 0.0818 - acc: 0.9982 - mean_squared_error: 0.0275\n",
      "Epoch 8/100\n",
      "3344/3344 [==============================] - 1s 208us/sample - loss: 0.0769 - acc: 0.9994 - mean_squared_error: 0.0253\n",
      "Epoch 9/100\n",
      "3344/3344 [==============================] - 1s 191us/sample - loss: 0.0727 - acc: 0.9997 - mean_squared_error: 0.0233\n",
      "Epoch 10/100\n",
      "3344/3344 [==============================] - 1s 185us/sample - loss: 0.0691 - acc: 0.9994 - mean_squared_error: 0.0216\n",
      "Epoch 11/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 0.0653 - acc: 0.9997 - mean_squared_error: 0.0198\n",
      "Epoch 12/100\n",
      "3344/3344 [==============================] - 1s 186us/sample - loss: 0.0618 - acc: 0.9997 - mean_squared_error: 0.0182\n",
      "Epoch 13/100\n",
      "3344/3344 [==============================] - 1s 189us/sample - loss: 0.0584 - acc: 0.9997 - mean_squared_error: 0.0166\n",
      "Epoch 14/100\n",
      "3344/3344 [==============================] - 1s 188us/sample - loss: 0.0552 - acc: 1.0000 - mean_squared_error: 0.0152\n",
      "Epoch 15/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 0.0521 - acc: 1.0000 - mean_squared_error: 0.0139\n",
      "Epoch 16/100\n",
      "3344/3344 [==============================] - 1s 184us/sample - loss: 0.0493 - acc: 1.0000 - mean_squared_error: 0.0126\n",
      "Epoch 17/100\n",
      "3344/3344 [==============================] - 1s 185us/sample - loss: 0.0465 - acc: 1.0000 - mean_squared_error: 0.0115\n",
      "Epoch 18/100\n",
      "3344/3344 [==============================] - 1s 186us/sample - loss: 0.0440 - acc: 1.0000 - mean_squared_error: 0.0105\n",
      "Epoch 19/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 0.0416 - acc: 1.0000 - mean_squared_error: 0.0095\n",
      "Epoch 20/100\n",
      "3344/3344 [==============================] - 1s 184us/sample - loss: 0.0393 - acc: 1.0000 - mean_squared_error: 0.0086\n",
      "Epoch 21/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 0.0372 - acc: 1.0000 - mean_squared_error: 0.0078\n",
      "Epoch 22/100\n",
      "3344/3344 [==============================] - 1s 203us/sample - loss: 0.0351 - acc: 1.0000 - mean_squared_error: 0.0071\n",
      "Epoch 23/100\n",
      "3344/3344 [==============================] - 1s 191us/sample - loss: 0.0332 - acc: 1.0000 - mean_squared_error: 0.0064\n",
      "Epoch 24/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 0.0314 - acc: 1.0000 - mean_squared_error: 0.0058\n",
      "Epoch 25/100\n",
      "3344/3344 [==============================] - 1s 182us/sample - loss: 0.0297 - acc: 1.0000 - mean_squared_error: 0.0053\n",
      "Epoch 26/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 0.0282 - acc: 1.0000 - mean_squared_error: 0.0048\n",
      "Epoch 27/100\n",
      "3344/3344 [==============================] - 1s 181us/sample - loss: 0.0267 - acc: 1.0000 - mean_squared_error: 0.0044\n",
      "Epoch 28/100\n",
      "3344/3344 [==============================] - 1s 181us/sample - loss: 0.0253 - acc: 1.0000 - mean_squared_error: 0.0039\n",
      "Epoch 29/100\n",
      "3344/3344 [==============================] - 1s 184us/sample - loss: 0.0239 - acc: 1.0000 - mean_squared_error: 0.0036\n",
      "Epoch 30/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 0.0227 - acc: 1.0000 - mean_squared_error: 0.0032\n",
      "Epoch 31/100\n",
      "3344/3344 [==============================] - 1s 186us/sample - loss: 0.0215 - acc: 1.0000 - mean_squared_error: 0.0029\n",
      "Epoch 32/100\n",
      "3344/3344 [==============================] - 1s 181us/sample - loss: 0.0204 - acc: 1.0000 - mean_squared_error: 0.0027\n",
      "Epoch 33/100\n",
      "3344/3344 [==============================] - 1s 202us/sample - loss: 0.0193 - acc: 1.0000 - mean_squared_error: 0.0024\n",
      "Epoch 34/100\n",
      "3344/3344 [==============================] - 1s 212us/sample - loss: 0.0184 - acc: 1.0000 - mean_squared_error: 0.0022\n",
      "Epoch 35/100\n",
      "3344/3344 [==============================] - 1s 186us/sample - loss: 0.0174 - acc: 1.0000 - mean_squared_error: 0.0020\n",
      "Epoch 36/100\n",
      "3344/3344 [==============================] - 1s 186us/sample - loss: 0.0165 - acc: 1.0000 - mean_squared_error: 0.0018\n",
      "Epoch 37/100\n",
      "3344/3344 [==============================] - 1s 184us/sample - loss: 0.0157 - acc: 1.0000 - mean_squared_error: 0.0016\n",
      "Epoch 38/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 0.0149 - acc: 1.0000 - mean_squared_error: 0.0015\n",
      "Epoch 39/100\n",
      "3344/3344 [==============================] - 1s 185us/sample - loss: 0.0142 - acc: 1.0000 - mean_squared_error: 0.0013\n",
      "Epoch 40/100\n",
      "3344/3344 [==============================] - 1s 182us/sample - loss: 0.0135 - acc: 1.0000 - mean_squared_error: 0.0012\n",
      "Epoch 41/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 0.0128 - acc: 1.0000 - mean_squared_error: 0.0011\n",
      "Epoch 42/100\n",
      "3344/3344 [==============================] - 1s 185us/sample - loss: 0.0122 - acc: 1.0000 - mean_squared_error: 0.0010\n",
      "Epoch 43/100\n",
      "3344/3344 [==============================] - 1s 180us/sample - loss: 0.0116 - acc: 1.0000 - mean_squared_error: 9.1639e-04\n",
      "Epoch 44/100\n",
      "3344/3344 [==============================] - 1s 181us/sample - loss: 0.0110 - acc: 1.0000 - mean_squared_error: 8.3235e-04\n",
      "Epoch 45/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 0.0105 - acc: 1.0000 - mean_squared_error: 7.5630e-04\n",
      "Epoch 46/100\n",
      "3344/3344 [==============================] - 1s 179us/sample - loss: 0.0100 - acc: 1.0000 - mean_squared_error: 6.8742e-04\n",
      "Epoch 47/100\n",
      "3344/3344 [==============================] - 1s 179us/sample - loss: 0.0095 - acc: 1.0000 - mean_squared_error: 6.2472e-04\n",
      "Epoch 48/100\n",
      "3344/3344 [==============================] - 1s 179us/sample - loss: 0.0090 - acc: 1.0000 - mean_squared_error: 5.6784e-04\n",
      "Epoch 49/100\n",
      "3344/3344 [==============================] - 1s 181us/sample - loss: 0.0086 - acc: 1.0000 - mean_squared_error: 5.1624e-04\n",
      "Epoch 50/100\n",
      "3344/3344 [==============================] - 1s 181us/sample - loss: 0.0082 - acc: 1.0000 - mean_squared_error: 4.6959e-04\n",
      "Epoch 51/100\n",
      "3344/3344 [==============================] - 1s 181us/sample - loss: 0.0078 - acc: 1.0000 - mean_squared_error: 4.2716e-04\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3344/3344 [==============================] - 1s 181us/sample - loss: 0.0074 - acc: 1.0000 - mean_squared_error: 3.8861e-04\n",
      "Epoch 53/100\n",
      "3344/3344 [==============================] - 1s 197us/sample - loss: 0.0071 - acc: 1.0000 - mean_squared_error: 3.5355e-04\n",
      "Epoch 54/100\n",
      "3344/3344 [==============================] - 1s 198us/sample - loss: 0.0067 - acc: 1.0000 - mean_squared_error: 3.2181e-04\n",
      "Epoch 55/100\n",
      "3344/3344 [==============================] - 1s 185us/sample - loss: 0.0064 - acc: 1.0000 - mean_squared_error: 2.9292e-04\n",
      "Epoch 56/100\n",
      "3344/3344 [==============================] - 1s 179us/sample - loss: 0.0061 - acc: 1.0000 - mean_squared_error: 2.6673e-04\n",
      "Epoch 57/100\n",
      "3344/3344 [==============================] - 1s 181us/sample - loss: 0.0058 - acc: 1.0000 - mean_squared_error: 2.4284e-04\n",
      "Epoch 58/100\n",
      "3344/3344 [==============================] - 1s 179us/sample - loss: 0.0056 - acc: 1.0000 - mean_squared_error: 2.2100e-04\n",
      "Epoch 59/100\n",
      "3344/3344 [==============================] - 1s 197us/sample - loss: 0.0053 - acc: 1.0000 - mean_squared_error: 2.0132e-04\n",
      "Epoch 60/100\n",
      "3344/3344 [==============================] - 1s 199us/sample - loss: 0.0051 - acc: 1.0000 - mean_squared_error: 1.8334e-04\n",
      "Epoch 61/100\n",
      "3344/3344 [==============================] - 1s 184us/sample - loss: 0.0048 - acc: 1.0000 - mean_squared_error: 1.6707e-04\n",
      "Epoch 62/100\n",
      "3344/3344 [==============================] - ETA: 0s - loss: 0.0046 - acc: 1.0000 - mean_squared_error: 1.5202e- - 1s 182us/sample - loss: 0.0046 - acc: 1.0000 - mean_squared_error: 1.5222e-04\n",
      "Epoch 63/100\n",
      "3344/3344 [==============================] - 1s 181us/sample - loss: 0.0044 - acc: 1.0000 - mean_squared_error: 1.3874e-04\n",
      "Epoch 64/100\n",
      "3344/3344 [==============================] - 1s 179us/sample - loss: 0.0042 - acc: 1.0000 - mean_squared_error: 1.2638e-04\n",
      "Epoch 65/100\n",
      "3344/3344 [==============================] - 1s 180us/sample - loss: 0.0040 - acc: 1.0000 - mean_squared_error: 1.1514e-04\n",
      "Epoch 66/100\n",
      "3344/3344 [==============================] - 1s 180us/sample - loss: 0.0038 - acc: 1.0000 - mean_squared_error: 1.0493e-04\n",
      "Epoch 67/100\n",
      "3344/3344 [==============================] - 1s 179us/sample - loss: 0.0036 - acc: 1.0000 - mean_squared_error: 9.5662e-05\n",
      "Epoch 68/100\n",
      "3344/3344 [==============================] - 1s 182us/sample - loss: 0.0035 - acc: 1.0000 - mean_squared_error: 8.7243e-05\n",
      "Epoch 69/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 0.0033 - acc: 1.0000 - mean_squared_error: 7.9566e-05\n",
      "Epoch 70/100\n",
      "3344/3344 [==============================] - 1s 178us/sample - loss: 0.0032 - acc: 1.0000 - mean_squared_error: 7.2573e-05\n",
      "Epoch 71/100\n",
      "3344/3344 [==============================] - 1s 180us/sample - loss: 0.0030 - acc: 1.0000 - mean_squared_error: 6.6259e-05\n",
      "Epoch 72/100\n",
      "3344/3344 [==============================] - 1s 177us/sample - loss: 0.0042 - acc: 0.9991 - mean_squared_error: 5.6241e-04\n",
      "Epoch 73/100\n",
      "3344/3344 [==============================] - 1s 179us/sample - loss: 0.0029 - acc: 1.0000 - mean_squared_error: 8.6083e-05\n",
      "Epoch 74/100\n",
      "3344/3344 [==============================] - 1s 178us/sample - loss: 0.0026 - acc: 1.0000 - mean_squared_error: 5.0660e-05 - loss: 0.0028 - acc: 1.0000 - mean_squ\n",
      "Epoch 75/100\n",
      "3344/3344 [==============================] - 1s 180us/sample - loss: 0.0025 - acc: 1.0000 - mean_squared_error: 4.6273e-05 - loss: 0.0024 - acc: 1.0000 - mean_squar\n",
      "Epoch 76/100\n",
      "3344/3344 [==============================] - 1s 180us/sample - loss: 0.0024 - acc: 1.0000 - mean_squared_error: 4.2285e-05\n",
      "Epoch 77/100\n",
      "3344/3344 [==============================] - 1s 180us/sample - loss: 0.0023 - acc: 1.0000 - mean_squared_error: 3.8626e-05\n",
      "Epoch 78/100\n",
      "3344/3344 [==============================] - 1s 181us/sample - loss: 0.0022 - acc: 1.0000 - mean_squared_error: 3.5291e-05\n",
      "Epoch 79/100\n",
      "3344/3344 [==============================] - 1s 181us/sample - loss: 0.0021 - acc: 1.0000 - mean_squared_error: 3.2233e-05\n",
      "Epoch 80/100\n",
      "3344/3344 [==============================] - 1s 179us/sample - loss: 0.0020 - acc: 1.0000 - mean_squared_error: 2.9445e-05\n",
      "Epoch 81/100\n",
      "3344/3344 [==============================] - 1s 180us/sample - loss: 0.0019 - acc: 1.0000 - mean_squared_error: 2.6897e-05\n",
      "Epoch 82/100\n",
      "3344/3344 [==============================] - 1s 186us/sample - loss: 0.0018 - acc: 1.0000 - mean_squared_error: 2.4565e-05\n",
      "Epoch 83/100\n",
      "3344/3344 [==============================] - 1s 184us/sample - loss: 0.0017 - acc: 1.0000 - mean_squared_error: 2.2441e-05\n",
      "Epoch 84/100\n",
      "3344/3344 [==============================] - 1s 211us/sample - loss: 0.0017 - acc: 1.0000 - mean_squared_error: 2.0503e-05\n",
      "Epoch 85/100\n",
      "3344/3344 [==============================] - 1s 252us/sample - loss: 0.0016 - acc: 1.0000 - mean_squared_error: 1.8727e-05\n",
      "Epoch 86/100\n",
      "3344/3344 [==============================] - 1s 208us/sample - loss: 0.0015 - acc: 1.0000 - mean_squared_error: 1.7100e-05\n",
      "Epoch 87/100\n",
      "3344/3344 [==============================] - 1s 216us/sample - loss: 0.0015 - acc: 1.0000 - mean_squared_error: 1.5619e-05\n",
      "Epoch 88/100\n",
      "3344/3344 [==============================] - 1s 205us/sample - loss: 0.0014 - acc: 1.0000 - mean_squared_error: 1.4268e-05\n",
      "Epoch 89/100\n",
      "3344/3344 [==============================] - 1s 179us/sample - loss: 0.0013 - acc: 1.0000 - mean_squared_error: 1.3031e-05\n",
      "Epoch 90/100\n",
      "3344/3344 [==============================] - 1s 189us/sample - loss: 0.0013 - acc: 1.0000 - mean_squared_error: 1.1902e-05\n",
      "Epoch 91/100\n",
      "3344/3344 [==============================] - 1s 218us/sample - loss: 0.0012 - acc: 1.0000 - mean_squared_error: 1.0873e-05\n",
      "Epoch 92/100\n",
      "3344/3344 [==============================] - 1s 225us/sample - loss: 0.0012 - acc: 1.0000 - mean_squared_error: 9.9339e-06\n",
      "Epoch 93/100\n",
      "3344/3344 [==============================] - 1s 224us/sample - loss: 0.0011 - acc: 1.0000 - mean_squared_error: 9.0744e-06\n",
      "Epoch 94/100\n",
      "3344/3344 [==============================] - 1s 227us/sample - loss: 0.0011 - acc: 1.0000 - mean_squared_error: 8.2864e-06\n",
      "Epoch 95/100\n",
      "3344/3344 [==============================] - 1s 214us/sample - loss: 0.0010 - acc: 1.0000 - mean_squared_error: 7.5681e-06\n",
      "Epoch 96/100\n",
      "3344/3344 [==============================] - 1s 216us/sample - loss: 9.6666e-04 - acc: 1.0000 - mean_squared_error: 6.9098e-06\n",
      "Epoch 97/100\n",
      "3344/3344 [==============================] - 1s 199us/sample - loss: 9.2370e-04 - acc: 1.0000 - mean_squared_error: 6.3113e-06\n",
      "Epoch 98/100\n",
      "3344/3344 [==============================] - 1s 185us/sample - loss: 8.8277e-04 - acc: 1.0000 - mean_squared_error: 5.7661e-06\n",
      "Epoch 99/100\n",
      "3344/3344 [==============================] - 1s 181us/sample - loss: 8.4362e-04 - acc: 1.0000 - mean_squared_error: 5.2676e-06\n",
      "Epoch 100/100\n",
      "3344/3344 [==============================] - 1s 182us/sample - loss: 8.0617e-04 - acc: 1.0000 - mean_squared_error: 4.8116e-06\n",
      "1115/1115 [==============================] - 0s 318us/sample - loss: 0.5718 - acc: 0.9722 - mean_squared_error: 0.0263\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_110 (Dense)            (None, 8)                 57064     \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 57,505\n",
      "Trainable params: 57,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3344/3344 [==============================] - 1s 306us/sample - loss: 0.4821 - acc: 0.8669 - mean_squared_error: 0.1586\n",
      "Epoch 2/100\n",
      "3344/3344 [==============================] - 1s 210us/sample - loss: 0.1759 - acc: 0.8938 - mean_squared_error: 0.0554\n",
      "Epoch 3/100\n",
      "3344/3344 [==============================] - 1s 210us/sample - loss: 0.0624 - acc: 0.9937 - mean_squared_error: 0.0155\n",
      "Epoch 4/100\n",
      "3344/3344 [==============================] - 1s 208us/sample - loss: 0.0155 - acc: 0.9970 - mean_squared_error: 0.0030\n",
      "Epoch 5/100\n",
      "3344/3344 [==============================] - 1s 202us/sample - loss: 0.0078 - acc: 0.9982 - mean_squared_error: 0.0015\n",
      "Epoch 6/100\n",
      "3344/3344 [==============================] - 1s 203us/sample - loss: 0.0050 - acc: 0.9988 - mean_squared_error: 9.7390e-04\n",
      "Epoch 7/100\n",
      "3344/3344 [==============================] - 1s 198us/sample - loss: 0.0021 - acc: 0.9997 - mean_squared_error: 3.3788e-04\n",
      "Epoch 8/100\n",
      "3344/3344 [==============================] - 1s 200us/sample - loss: 0.0012 - acc: 0.9997 - mean_squared_error: 2.3314e-04\n",
      "Epoch 9/100\n",
      "3344/3344 [==============================] - 1s 203us/sample - loss: 4.8184e-04 - acc: 1.0000 - mean_squared_error: 1.9861e-05\n",
      "Epoch 10/100\n",
      "3344/3344 [==============================] - 1s 179us/sample - loss: 3.2272e-04 - acc: 1.0000 - mean_squared_error: 9.9287e-06\n",
      "Epoch 11/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 2.4356e-04 - acc: 1.0000 - mean_squared_error: 6.8989e-06\n",
      "Epoch 12/100\n",
      "3344/3344 [==============================] - 1s 181us/sample - loss: 1.8592e-04 - acc: 1.0000 - mean_squared_error: 4.5155e-06\n",
      "Epoch 13/100\n",
      "3344/3344 [==============================] - 1s 181us/sample - loss: 1.4874e-04 - acc: 1.0000 - mean_squared_error: 3.1648e-06\n",
      "Epoch 14/100\n",
      "3344/3344 [==============================] - 1s 185us/sample - loss: 1.2148e-04 - acc: 1.0000 - mean_squared_error: 2.2283e-06\n",
      "Epoch 15/100\n",
      "3344/3344 [==============================] - 1s 179us/sample - loss: 1.0109e-04 - acc: 1.0000 - mean_squared_error: 1.5906e-06\n",
      "Epoch 16/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 8.4362e-05 - acc: 1.0000 - mean_squared_error: 1.2140e-06\n",
      "Epoch 17/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 7.1247e-05 - acc: 1.0000 - mean_squared_error: 8.4774e-07\n",
      "Epoch 18/100\n",
      "3344/3344 [==============================] - 1s 182us/sample - loss: 6.0721e-05 - acc: 1.0000 - mean_squared_error: 6.5233e-07\n",
      "Epoch 19/100\n",
      "3344/3344 [==============================] - 1s 186us/sample - loss: 5.2496e-05 - acc: 1.0000 - mean_squared_error: 4.9014e-07\n",
      "Epoch 20/100\n",
      "3344/3344 [==============================] - 1s 185us/sample - loss: 4.5766e-05 - acc: 1.0000 - mean_squared_error: 3.8608e-07\n",
      "Epoch 21/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 4.0095e-05 - acc: 1.0000 - mean_squared_error: 2.9924e-07\n",
      "Epoch 22/100\n",
      "3344/3344 [==============================] - 1s 184us/sample - loss: 3.5296e-05 - acc: 1.0000 - mean_squared_error: 2.5452e-07\n",
      "Epoch 23/100\n",
      "3344/3344 [==============================] - 1s 188us/sample - loss: 3.1307e-05 - acc: 1.0000 - mean_squared_error: 2.0246e-07\n",
      "Epoch 24/100\n",
      "3344/3344 [==============================] - 1s 182us/sample - loss: 2.7792e-05 - acc: 1.0000 - mean_squared_error: 1.6268e-07\n",
      "Epoch 25/100\n",
      "3344/3344 [==============================] - 1s 184us/sample - loss: 2.4816e-05 - acc: 1.0000 - mean_squared_error: 1.3345e-07\n",
      "Epoch 26/100\n",
      "3344/3344 [==============================] - 1s 185us/sample - loss: 2.2162e-05 - acc: 1.0000 - mean_squared_error: 1.0717e-07\n",
      "Epoch 27/100\n",
      "3344/3344 [==============================] - 1s 184us/sample - loss: 1.9941e-05 - acc: 1.0000 - mean_squared_error: 8.9130e-08\n",
      "Epoch 28/100\n",
      "3344/3344 [==============================] - 1s 187us/sample - loss: 1.7950e-05 - acc: 1.0000 - mean_squared_error: 7.1838e-08\n",
      "Epoch 29/100\n",
      "3344/3344 [==============================] - 1s 202us/sample - loss: 1.6081e-05 - acc: 1.0000 - mean_squared_error: 5.8627e-08\n",
      "Epoch 30/100\n",
      "3344/3344 [==============================] - 1s 199us/sample - loss: 1.4486e-05 - acc: 1.0000 - mean_squared_error: 4.7965e-08\n",
      "Epoch 31/100\n",
      "3344/3344 [==============================] - 1s 190us/sample - loss: 1.3150e-05 - acc: 1.0000 - mean_squared_error: 3.9943e-08\n",
      "Epoch 32/100\n",
      "3344/3344 [==============================] - 1s 182us/sample - loss: 1.1882e-05 - acc: 1.0000 - mean_squared_error: 3.3310e-08\n",
      "Epoch 33/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 1.0799e-05 - acc: 1.0000 - mean_squared_error: 2.7419e-08\n",
      "Epoch 34/100\n",
      "3344/3344 [==============================] - 1s 180us/sample - loss: 9.8259e-06 - acc: 1.0000 - mean_squared_error: 2.3247e-08\n",
      "Epoch 35/100\n",
      "3344/3344 [==============================] - 1s 182us/sample - loss: 8.9417e-06 - acc: 1.0000 - mean_squared_error: 1.9816e-08\n",
      "Epoch 36/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 8.1838e-06 - acc: 1.0000 - mean_squared_error: 1.6363e-08\n",
      "Epoch 37/100\n",
      "3344/3344 [==============================] - 1s 184us/sample - loss: 7.4020e-06 - acc: 1.0000 - mean_squared_error: 1.3114e-08\n",
      "Epoch 38/100\n",
      "3344/3344 [==============================] - 1s 182us/sample - loss: 6.7702e-06 - acc: 1.0000 - mean_squared_error: 1.1582e-08\n",
      "Epoch 39/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 6.1766e-06 - acc: 1.0000 - mean_squared_error: 9.4050e-09\n",
      "Epoch 40/100\n",
      "3344/3344 [==============================] - ETA: 0s - loss: 5.7264e-06 - acc: 1.0000 - mean_squared_error: 7.9781e- - 1s 184us/sample - loss: 5.5967e-06 - acc: 1.0000 - mean_squared_error: 7.7325e-09\n",
      "Epoch 41/100\n",
      "3344/3344 [==============================] - 1s 186us/sample - loss: 5.1467e-06 - acc: 1.0000 - mean_squared_error: 6.5993e-09\n",
      "Epoch 42/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 4.7204e-06 - acc: 1.0000 - mean_squared_error: 5.7783e-09\n",
      "Epoch 43/100\n",
      "3344/3344 [==============================] - 1s 186us/sample - loss: 4.3097e-06 - acc: 1.0000 - mean_squared_error: 4.6184e-09\n",
      "Epoch 44/100\n",
      "3344/3344 [==============================] - 1s 182us/sample - loss: 3.9500e-06 - acc: 1.0000 - mean_squared_error: 4.0388e-09\n",
      "Epoch 45/100\n",
      "3344/3344 [==============================] - 1s 181us/sample - loss: 3.6246e-06 - acc: 1.0000 - mean_squared_error: 3.4015e-09 - loss: 3.3237e-06 - acc: 1.0000 - mean_squared\n",
      "Epoch 46/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 3.3278e-06 - acc: 1.0000 - mean_squared_error: 2.9153e-09\n",
      "Epoch 47/100\n",
      "3344/3344 [==============================] - 1s 182us/sample - loss: 3.0709e-06 - acc: 1.0000 - mean_squared_error: 2.4768e-09\n",
      "Epoch 48/100\n",
      "3344/3344 [==============================] - 1s 185us/sample - loss: 2.8195e-06 - acc: 1.0000 - mean_squared_error: 2.1277e-09\n",
      "Epoch 49/100\n",
      "3344/3344 [==============================] - 1s 185us/sample - loss: 2.5911e-06 - acc: 1.0000 - mean_squared_error: 1.8299e-09\n",
      "Epoch 50/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 2.3961e-06 - acc: 1.0000 - mean_squared_error: 1.5749e-09\n",
      "Epoch 51/100\n",
      "3344/3344 [==============================] - ETA: 0s - loss: 2.2738e-06 - acc: 1.0000 - mean_squared_error: 1.4172e- - 1s 183us/sample - loss: 2.2290e-06 - acc: 1.0000 - mean_squared_error: 1.3859e-09\n",
      "Epoch 52/100\n",
      "3344/3344 [==============================] - 1s 182us/sample - loss: 2.0454e-06 - acc: 1.0000 - mean_squared_error: 1.1549e-09\n",
      "Epoch 53/100\n",
      "3344/3344 [==============================] - 1s 188us/sample - loss: 1.9010e-06 - acc: 1.0000 - mean_squared_error: 1.0131e-09\n",
      "Epoch 54/100\n",
      "3344/3344 [==============================] - 1s 204us/sample - loss: 1.7489e-06 - acc: 1.0000 - mean_squared_error: 8.3625e-10\n",
      "Epoch 55/100\n",
      "3344/3344 [==============================] - 1s 207us/sample - loss: 1.6132e-06 - acc: 1.0000 - mean_squared_error: 7.3388e-10\n",
      "Epoch 56/100\n",
      "3344/3344 [==============================] - 1s 203us/sample - loss: 1.4986e-06 - acc: 1.0000 - mean_squared_error: 6.2586e-10\n",
      "Epoch 57/100\n",
      "3344/3344 [==============================] - 1s 187us/sample - loss: 1.3852e-06 - acc: 1.0000 - mean_squared_error: 5.4814e-10\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3344/3344 [==============================] - 1s 184us/sample - loss: 1.2803e-06 - acc: 1.0000 - mean_squared_error: 4.6566e-10\n",
      "Epoch 59/100\n",
      "3344/3344 [==============================] - 1s 182us/sample - loss: 1.1703e-06 - acc: 1.0000 - mean_squared_error: 3.7670e-10\n",
      "Epoch 60/100\n",
      "3344/3344 [==============================] - 1s 184us/sample - loss: 1.0779e-06 - acc: 1.0000 - mean_squared_error: 3.2626e-10\n",
      "Epoch 61/100\n",
      "3344/3344 [==============================] - 1s 181us/sample - loss: 1.0021e-06 - acc: 1.0000 - mean_squared_error: 2.7549e-10\n",
      "Epoch 62/100\n",
      "3344/3344 [==============================] - 1s 184us/sample - loss: 9.2386e-07 - acc: 1.0000 - mean_squared_error: 2.3939e-10\n",
      "Epoch 63/100\n",
      "3344/3344 [==============================] - 1s 181us/sample - loss: 8.5682e-07 - acc: 1.0000 - mean_squared_error: 2.0491e-10\n",
      "Epoch 64/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 7.9684e-07 - acc: 1.0000 - mean_squared_error: 1.7200e-10\n",
      "Epoch 65/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 7.3983e-07 - acc: 1.0000 - mean_squared_error: 1.5117e-10\n",
      "Epoch 66/100\n",
      "3344/3344 [==============================] - 1s 180us/sample - loss: 6.8501e-07 - acc: 1.0000 - mean_squared_error: 1.2889e-10\n",
      "Epoch 67/100\n",
      "3344/3344 [==============================] - 1s 180us/sample - loss: 6.3884e-07 - acc: 1.0000 - mean_squared_error: 1.1351e-10\n",
      "Epoch 68/100\n",
      "3344/3344 [==============================] - 1s 184us/sample - loss: 5.9107e-07 - acc: 1.0000 - mean_squared_error: 9.7104e-11\n",
      "Epoch 69/100\n",
      "3344/3344 [==============================] - 1s 191us/sample - loss: 5.4932e-07 - acc: 1.0000 - mean_squared_error: 8.2124e-11\n",
      "Epoch 70/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 5.0676e-07 - acc: 1.0000 - mean_squared_error: 6.9894e-11\n",
      "Epoch 71/100\n",
      "3344/3344 [==============================] - 1s 182us/sample - loss: 4.7363e-07 - acc: 1.0000 - mean_squared_error: 6.1707e-11\n",
      "Epoch 72/100\n",
      "3344/3344 [==============================] - 1s 185us/sample - loss: 4.3853e-07 - acc: 1.0000 - mean_squared_error: 5.2347e-11\n",
      "Epoch 73/100\n",
      "3344/3344 [==============================] - 1s 182us/sample - loss: 4.0892e-07 - acc: 1.0000 - mean_squared_error: 4.4969e-11\n",
      "Epoch 74/100\n",
      "3344/3344 [==============================] - 1s 180us/sample - loss: 3.7851e-07 - acc: 1.0000 - mean_squared_error: 3.8663e-11\n",
      "Epoch 75/100\n",
      "3344/3344 [==============================] - 1s 182us/sample - loss: 3.5168e-07 - acc: 1.0000 - mean_squared_error: 3.3502e-11\n",
      "Epoch 76/100\n",
      "3344/3344 [==============================] - 1s 186us/sample - loss: 3.2604e-07 - acc: 1.0000 - mean_squared_error: 2.8169e-11\n",
      "Epoch 77/100\n",
      "3344/3344 [==============================] - 1s 181us/sample - loss: 3.0729e-07 - acc: 1.0000 - mean_squared_error: 2.5240e-11\n",
      "Epoch 78/100\n",
      "3344/3344 [==============================] - 1s 190us/sample - loss: 2.8297e-07 - acc: 1.0000 - mean_squared_error: 2.1546e-11\n",
      "Epoch 79/100\n",
      "3344/3344 [==============================] - 1s 200us/sample - loss: 2.6272e-07 - acc: 1.0000 - mean_squared_error: 1.8669e-11\n",
      "Epoch 80/100\n",
      "3344/3344 [==============================] - 1s 212us/sample - loss: 2.4306e-07 - acc: 1.0000 - mean_squared_error: 1.5904e-11\n",
      "Epoch 81/100\n",
      "3344/3344 [==============================] - 1s 185us/sample - loss: 2.2586e-07 - acc: 1.0000 - mean_squared_error: 1.3641e-11\n",
      "Epoch 82/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 2.1064e-07 - acc: 1.0000 - mean_squared_error: 1.1404e-11\n",
      "Epoch 83/100\n",
      "3344/3344 [==============================] - 1s 181us/sample - loss: 1.9532e-07 - acc: 1.0000 - mean_squared_error: 1.0192e-11\n",
      "Epoch 84/100\n",
      "3344/3344 [==============================] - 1s 186us/sample - loss: 1.8112e-07 - acc: 1.0000 - mean_squared_error: 8.6088e-12\n",
      "Epoch 85/100\n",
      "3344/3344 [==============================] - 1s 182us/sample - loss: 1.6931e-07 - acc: 1.0000 - mean_squared_error: 7.6294e-12\n",
      "Epoch 86/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 1.5643e-07 - acc: 1.0000 - mean_squared_error: 6.3303e-12\n",
      "Epoch 87/100\n",
      "3344/3344 [==============================] - 1s 182us/sample - loss: 1.4514e-07 - acc: 1.0000 - mean_squared_error: 5.5772e-12\n",
      "Epoch 88/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 1.3614e-07 - acc: 1.0000 - mean_squared_error: 4.8124e-12\n",
      "Epoch 89/100\n",
      "3344/3344 [==============================] - 1s 182us/sample - loss: 1.2562e-07 - acc: 1.0000 - mean_squared_error: 4.1180e-12\n",
      "Epoch 90/100\n",
      "3344/3344 [==============================] - 1s 180us/sample - loss: 1.1710e-07 - acc: 1.0000 - mean_squared_error: 3.5237e-12\n",
      "Epoch 91/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 1.0882e-07 - acc: 1.0000 - mean_squared_error: 3.0205e-12\n",
      "Epoch 92/100\n",
      "3344/3344 [==============================] - 1s 182us/sample - loss: 1.0225e-07 - acc: 1.0000 - mean_squared_error: 2.7116e-12\n",
      "Epoch 93/100\n",
      "3344/3344 [==============================] - 1s 181us/sample - loss: 9.4532e-08 - acc: 1.0000 - mean_squared_error: 2.3138e-12\n",
      "Epoch 94/100\n",
      "3344/3344 [==============================] - 1s 184us/sample - loss: 8.8316e-08 - acc: 1.0000 - mean_squared_error: 1.9993e-12\n",
      "Epoch 95/100\n",
      "3344/3344 [==============================] - 1s 179us/sample - loss: 8.2584e-08 - acc: 1.0000 - mean_squared_error: 1.7448e-12\n",
      "Epoch 96/100\n",
      "3344/3344 [==============================] - 1s 233us/sample - loss: 7.6630e-08 - acc: 1.0000 - mean_squared_error: 1.5017e-12\n",
      "Epoch 97/100\n",
      "3344/3344 [==============================] - 1s 213us/sample - loss: 7.1594e-08 - acc: 1.0000 - mean_squared_error: 1.3085e-12\n",
      "Epoch 98/100\n",
      "3344/3344 [==============================] - 1s 191us/sample - loss: 6.6985e-08 - acc: 1.0000 - mean_squared_error: 1.1125e-12\n",
      "Epoch 99/100\n",
      "3344/3344 [==============================] - 1s 184us/sample - loss: 6.2520e-08 - acc: 1.0000 - mean_squared_error: 1.0067e-12\n",
      "Epoch 100/100\n",
      "3344/3344 [==============================] - 1s 183us/sample - loss: 5.8469e-08 - acc: 1.0000 - mean_squared_error: 8.6156e-13\n",
      "1115/1115 [==============================] - 0s 326us/sample - loss: 0.2453 - acc: 0.9785 - mean_squared_error: 0.0195\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_118 (Dense)            (None, 8)                 57064     \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 57,505\n",
      "Trainable params: 57,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "3344/3344 [==============================] - 1s 335us/sample - loss: 0.5319 - acc: 0.8568 - mean_squared_error: 0.1781\n",
      "Epoch 2/100\n",
      "3344/3344 [==============================] - 1s 207us/sample - loss: 0.1547 - acc: 0.9214 - mean_squared_error: 0.0469\n",
      "Epoch 3/100\n",
      "3344/3344 [==============================] - 1s 208us/sample - loss: 0.0522 - acc: 0.9928 - mean_squared_error: 0.0121\n",
      "Epoch 4/100\n",
      "3344/3344 [==============================] - 1s 210us/sample - loss: 0.0139 - acc: 0.9961 - mean_squared_error: 0.0029\n",
      "Epoch 5/100\n",
      "3344/3344 [==============================] - 1s 212us/sample - loss: 0.0062 - acc: 0.9988 - mean_squared_error: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "3344/3344 [==============================] - 1s 208us/sample - loss: 0.0036 - acc: 0.9994 - mean_squared_error: 7.2673e-04\n",
      "Epoch 7/100\n",
      "3344/3344 [==============================] - 1s 213us/sample - loss: 0.0022 - acc: 0.9994 - mean_squared_error: 4.5206e-04\n",
      "Epoch 8/100\n",
      "3344/3344 [==============================] - 1s 191us/sample - loss: 0.0015 - acc: 0.9994 - mean_squared_error: 3.3553e-04\n",
      "Epoch 9/100\n",
      "3344/3344 [==============================] - 1s 186us/sample - loss: 0.0010 - acc: 0.9997 - mean_squared_error: 2.4645e-04\n",
      "Epoch 10/100\n",
      "3344/3344 [==============================] - 1s 190us/sample - loss: 7.9447e-04 - acc: 0.9997 - mean_squared_error: 1.6753e-04\n",
      "Epoch 11/100\n",
      "3344/3344 [==============================] - 1s 189us/sample - loss: 5.7374e-04 - acc: 0.9997 - mean_squared_error: 1.2139e-04\n",
      "Epoch 12/100\n",
      "3344/3344 [==============================] - 1s 190us/sample - loss: 4.5768e-04 - acc: 0.9997 - mean_squared_error: 9.1832e-05\n",
      "Epoch 13/100\n",
      "3344/3344 [==============================] - 1s 192us/sample - loss: 3.5611e-04 - acc: 1.0000 - mean_squared_error: 7.1421e-05\n",
      "Epoch 14/100\n",
      "3344/3344 [==============================] - 1s 190us/sample - loss: 2.7374e-04 - acc: 1.0000 - mean_squared_error: 3.7465e-05\n",
      "Epoch 15/100\n",
      "3344/3344 [==============================] - 1s 214us/sample - loss: 2.1528e-04 - acc: 1.0000 - mean_squared_error: 3.1594e-05\n",
      "Epoch 16/100\n",
      "3344/3344 [==============================] - 1s 214us/sample - loss: 1.7030e-04 - acc: 1.0000 - mean_squared_error: 1.6648e-05\n",
      "Epoch 17/100\n",
      "3344/3344 [==============================] - 1s 203us/sample - loss: 1.3413e-04 - acc: 1.0000 - mean_squared_error: 7.1844e-06\n",
      "Epoch 18/100\n",
      "3344/3344 [==============================] - 1s 187us/sample - loss: 1.1180e-04 - acc: 1.0000 - mean_squared_error: 7.7839e-06\n",
      "Epoch 19/100\n",
      "3344/3344 [==============================] - 1s 192us/sample - loss: 9.1059e-05 - acc: 1.0000 - mean_squared_error: 5.5967e-06\n",
      "Epoch 20/100\n",
      "3344/3344 [==============================] - 1s 206us/sample - loss: 7.6036e-05 - acc: 1.0000 - mean_squared_error: 3.4208e-06\n",
      "Epoch 21/100\n",
      "3344/3344 [==============================] - 1s 199us/sample - loss: 6.3460e-05 - acc: 1.0000 - mean_squared_error: 2.0077e-06\n",
      "Epoch 22/100\n",
      "3344/3344 [==============================] - 1s 206us/sample - loss: 5.4644e-05 - acc: 1.0000 - mean_squared_error: 1.9203e-06\n",
      "Epoch 23/100\n",
      "3344/3344 [==============================] - 1s 201us/sample - loss: 4.6774e-05 - acc: 1.0000 - mean_squared_error: 1.1158e-06\n",
      "Epoch 24/100\n",
      "3344/3344 [==============================] - 1s 188us/sample - loss: 4.0679e-05 - acc: 1.0000 - mean_squared_error: 9.0132e-07\n",
      "Epoch 25/100\n",
      "3344/3344 [==============================] - 1s 190us/sample - loss: 3.5346e-05 - acc: 1.0000 - mean_squared_error: 7.1802e-07\n",
      "Epoch 26/100\n",
      "3344/3344 [==============================] - 1s 185us/sample - loss: 3.0845e-05 - acc: 1.0000 - mean_squared_error: 4.5181e-07\n",
      "Epoch 27/100\n",
      "3344/3344 [==============================] - 1s 185us/sample - loss: 2.7235e-05 - acc: 1.0000 - mean_squared_error: 3.9159e-07\n",
      "Epoch 28/100\n",
      "3344/3344 [==============================] - 1s 191us/sample - loss: 2.4166e-05 - acc: 1.0000 - mean_squared_error: 2.8009e-07\n",
      "Epoch 29/100\n",
      "3344/3344 [==============================] - 1s 186us/sample - loss: 2.1470e-05 - acc: 1.0000 - mean_squared_error: 2.3426e-07\n",
      "Epoch 30/100\n",
      "3344/3344 [==============================] - 1s 187us/sample - loss: 1.9012e-05 - acc: 1.0000 - mean_squared_error: 1.6122e-07\n",
      "Epoch 31/100\n",
      "3344/3344 [==============================] - 1s 188us/sample - loss: 1.7007e-05 - acc: 1.0000 - mean_squared_error: 1.4132e-07\n",
      "Epoch 32/100\n",
      "3344/3344 [==============================] - 1s 185us/sample - loss: 1.5351e-05 - acc: 1.0000 - mean_squared_error: 1.1119e-07\n",
      "Epoch 33/100\n",
      "3344/3344 [==============================] - 1s 189us/sample - loss: 1.3938e-05 - acc: 1.0000 - mean_squared_error: 8.6132e-08\n",
      "Epoch 34/100\n",
      "3344/3344 [==============================] - 1s 188us/sample - loss: 1.2611e-05 - acc: 1.0000 - mean_squared_error: 6.6619e-08\n",
      "Epoch 35/100\n",
      "3344/3344 [==============================] - 1s 188us/sample - loss: 1.1380e-05 - acc: 1.0000 - mean_squared_error: 5.6054e-08\n",
      "Epoch 36/100\n",
      "3344/3344 [==============================] - 1s 187us/sample - loss: 1.0299e-05 - acc: 1.0000 - mean_squared_error: 4.7635e-08\n",
      "Epoch 37/100\n",
      "3344/3344 [==============================] - 1s 189us/sample - loss: 9.3983e-06 - acc: 1.0000 - mean_squared_error: 4.1234e-08\n",
      "Epoch 38/100\n",
      "3344/3344 [==============================] - 1s 187us/sample - loss: 8.6927e-06 - acc: 1.0000 - mean_squared_error: 3.7575e-08\n",
      "Epoch 39/100\n",
      "3344/3344 [==============================] - 1s 189us/sample - loss: 7.9922e-06 - acc: 1.0000 - mean_squared_error: 2.9652e-08\n",
      "Epoch 40/100\n",
      "3344/3344 [==============================] - 1s 186us/sample - loss: 7.2906e-06 - acc: 1.0000 - mean_squared_error: 2.6502e-08\n",
      "Epoch 41/100\n",
      "3344/3344 [==============================] - 1s 186us/sample - loss: 6.7753e-06 - acc: 1.0000 - mean_squared_error: 2.4069e-08\n",
      "Epoch 42/100\n",
      "3344/3344 [==============================] - 1s 186us/sample - loss: 6.2309e-06 - acc: 1.0000 - mean_squared_error: 2.0845e-08\n",
      "Epoch 43/100\n",
      "3344/3344 [==============================] - 1s 187us/sample - loss: 5.7604e-06 - acc: 1.0000 - mean_squared_error: 1.8140e-08\n",
      "Epoch 44/100\n",
      "3344/3344 [==============================] - 1s 191us/sample - loss: 5.3286e-06 - acc: 1.0000 - mean_squared_error: 1.5989e-08\n",
      "Epoch 45/100\n",
      "3344/3344 [==============================] - 1s 188us/sample - loss: 4.9213e-06 - acc: 1.0000 - mean_squared_error: 1.3880e-08\n",
      "Epoch 46/100\n",
      "3344/3344 [==============================] - 1s 202us/sample - loss: 4.5615e-06 - acc: 1.0000 - mean_squared_error: 1.1672e-08\n",
      "Epoch 47/100\n",
      "3344/3344 [==============================] - 1s 203us/sample - loss: 4.2235e-06 - acc: 1.0000 - mean_squared_error: 1.0386e-08\n",
      "Epoch 48/100\n",
      "3344/3344 [==============================] - 1s 191us/sample - loss: 3.9300e-06 - acc: 1.0000 - mean_squared_error: 9.3093e-09\n",
      "Epoch 49/100\n",
      "3344/3344 [==============================] - 1s 189us/sample - loss: 3.6395e-06 - acc: 1.0000 - mean_squared_error: 8.0680e-09\n",
      "Epoch 50/100\n",
      "3344/3344 [==============================] - 1s 186us/sample - loss: 3.3976e-06 - acc: 1.0000 - mean_squared_error: 7.0367e-09\n",
      "Epoch 51/100\n",
      "3344/3344 [==============================] - 1s 186us/sample - loss: 3.1362e-06 - acc: 1.0000 - mean_squared_error: 6.2484e-09\n",
      "Epoch 52/100\n",
      "3344/3344 [==============================] - 1s 189us/sample - loss: 2.9284e-06 - acc: 1.0000 - mean_squared_error: 5.4730e-09\n",
      "Epoch 53/100\n",
      "3344/3344 [==============================] - 1s 188us/sample - loss: 2.7067e-06 - acc: 1.0000 - mean_squared_error: 4.6704e-09\n",
      "Epoch 54/100\n",
      "3344/3344 [==============================] - 1s 189us/sample - loss: 2.4880e-06 - acc: 1.0000 - mean_squared_error: 3.8613e-09\n",
      "Epoch 55/100\n",
      "3344/3344 [==============================] - 1s 191us/sample - loss: 2.3261e-06 - acc: 1.0000 - mean_squared_error: 3.4822e-09\n",
      "Epoch 56/100\n",
      "3344/3344 [==============================] - 1s 192us/sample - loss: 2.1533e-06 - acc: 1.0000 - mean_squared_error: 3.0896e-09\n",
      "Epoch 57/100\n",
      "3344/3344 [==============================] - 1s 190us/sample - loss: 2.0170e-06 - acc: 1.0000 - mean_squared_error: 2.7438e-09\n",
      "Epoch 58/100\n",
      "3344/3344 [==============================] - 1s 191us/sample - loss: 1.8802e-06 - acc: 1.0000 - mean_squared_error: 2.4376e-09\n",
      "Epoch 59/100\n",
      "3344/3344 [==============================] - 1s 187us/sample - loss: 1.7486e-06 - acc: 1.0000 - mean_squared_error: 2.1479e-09\n",
      "Epoch 60/100\n",
      "3344/3344 [==============================] - 1s 187us/sample - loss: 1.6304e-06 - acc: 1.0000 - mean_squared_error: 1.9150e-09\n",
      "Epoch 61/100\n",
      "3344/3344 [==============================] - 1s 187us/sample - loss: 1.5315e-06 - acc: 1.0000 - mean_squared_error: 1.7672e-09\n",
      "Epoch 62/100\n",
      "3344/3344 [==============================] - 1s 185us/sample - loss: 1.4197e-06 - acc: 1.0000 - mean_squared_error: 1.4846e-09\n",
      "Epoch 63/100\n",
      "3344/3344 [==============================] - 1s 190us/sample - loss: 1.3287e-06 - acc: 1.0000 - mean_squared_error: 1.2874e-09\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3344/3344 [==============================] - 1s 186us/sample - loss: 1.2408e-06 - acc: 1.0000 - mean_squared_error: 1.1511e-09\n",
      "Epoch 65/100\n",
      "3344/3344 [==============================] - 1s 186us/sample - loss: 1.1558e-06 - acc: 1.0000 - mean_squared_error: 1.0156e-09\n",
      "Epoch 66/100\n",
      "3344/3344 [==============================] - 1s 188us/sample - loss: 1.0758e-06 - acc: 1.0000 - mean_squared_error: 8.9893e-10\n",
      "Epoch 67/100\n",
      "3344/3344 [==============================] - 1s 185us/sample - loss: 1.0103e-06 - acc: 1.0000 - mean_squared_error: 7.9807e-10\n",
      "Epoch 68/100\n",
      "3344/3344 [==============================] - 1s 189us/sample - loss: 9.4186e-07 - acc: 1.0000 - mean_squared_error: 6.9774e-10\n",
      "Epoch 69/100\n",
      "3344/3344 [==============================] - 1s 192us/sample - loss: 8.7957e-07 - acc: 1.0000 - mean_squared_error: 6.2080e-10\n",
      "Epoch 70/100\n",
      "3344/3344 [==============================] - 1s 189us/sample - loss: 8.2391e-07 - acc: 1.0000 - mean_squared_error: 5.4809e-10\n",
      "Epoch 71/100\n",
      "3344/3344 [==============================] - 1s 189us/sample - loss: 7.7232e-07 - acc: 1.0000 - mean_squared_error: 4.8736e-10\n",
      "Epoch 72/100\n",
      "3344/3344 [==============================] - 1s 200us/sample - loss: 7.1797e-07 - acc: 1.0000 - mean_squared_error: 4.3368e-10\n",
      "Epoch 73/100\n",
      "3344/3344 [==============================] - 1s 197us/sample - loss: 6.7144e-07 - acc: 1.0000 - mean_squared_error: 3.7824e-10\n",
      "Epoch 74/100\n",
      "3344/3344 [==============================] - 1s 198us/sample - loss: 6.2890e-07 - acc: 1.0000 - mean_squared_error: 3.4452e-10\n",
      "Epoch 75/100\n",
      "3344/3344 [==============================] - 1s 188us/sample - loss: 5.8936e-07 - acc: 1.0000 - mean_squared_error: 2.9212e-10\n",
      "Epoch 76/100\n",
      "3344/3344 [==============================] - 1s 187us/sample - loss: 5.4872e-07 - acc: 1.0000 - mean_squared_error: 2.5884e-10\n",
      "Epoch 77/100\n",
      "3344/3344 [==============================] - 1s 188us/sample - loss: 5.1316e-07 - acc: 1.0000 - mean_squared_error: 2.3218e-10\n",
      "Epoch 78/100\n",
      "3344/3344 [==============================] - 1s 187us/sample - loss: 4.8151e-07 - acc: 1.0000 - mean_squared_error: 2.0738e-10\n",
      "Epoch 79/100\n",
      "3344/3344 [==============================] - 1s 184us/sample - loss: 4.5046e-07 - acc: 1.0000 - mean_squared_error: 1.8102e-10\n",
      "Epoch 80/100\n",
      "3344/3344 [==============================] - 1s 188us/sample - loss: 4.2152e-07 - acc: 1.0000 - mean_squared_error: 1.6222e-10\n",
      "Epoch 81/100\n",
      "3344/3344 [==============================] - 1s 186us/sample - loss: 3.9364e-07 - acc: 1.0000 - mean_squared_error: 1.4242e-10 - loss: 1.1698e-07 - acc: 1.0000 - mean_squared\n",
      "Epoch 82/100\n",
      "3344/3344 [==============================] - 1s 189us/sample - loss: 3.6769e-07 - acc: 1.0000 - mean_squared_error: 1.2247e-10\n",
      "Epoch 83/100\n",
      "3344/3344 [==============================] - 1s 191us/sample - loss: 3.4541e-07 - acc: 1.0000 - mean_squared_error: 1.0817e-10\n",
      "Epoch 84/100\n",
      "3344/3344 [==============================] - 1s 185us/sample - loss: 3.2234e-07 - acc: 1.0000 - mean_squared_error: 9.5074e-11\n",
      "Epoch 85/100\n",
      "3344/3344 [==============================] - 1s 189us/sample - loss: 3.0198e-07 - acc: 1.0000 - mean_squared_error: 8.4344e-11\n",
      "Epoch 86/100\n",
      "3344/3344 [==============================] - 1s 189us/sample - loss: 2.8217e-07 - acc: 1.0000 - mean_squared_error: 7.4019e-11\n",
      "Epoch 87/100\n",
      "3344/3344 [==============================] - 1s 189us/sample - loss: 2.6483e-07 - acc: 1.0000 - mean_squared_error: 6.6948e-11\n",
      "Epoch 88/100\n",
      "3344/3344 [==============================] - 1s 187us/sample - loss: 2.4832e-07 - acc: 1.0000 - mean_squared_error: 5.6616e-11\n",
      "Epoch 89/100\n",
      "3344/3344 [==============================] - 1s 190us/sample - loss: 2.3193e-07 - acc: 1.0000 - mean_squared_error: 5.2085e-11\n",
      "Epoch 90/100\n",
      "3344/3344 [==============================] - 1s 187us/sample - loss: 2.1705e-07 - acc: 1.0000 - mean_squared_error: 4.5838e-11\n",
      "Epoch 91/100\n",
      "3344/3344 [==============================] - 1s 192us/sample - loss: 2.0409e-07 - acc: 1.0000 - mean_squared_error: 4.0580e-11\n",
      "Epoch 92/100\n",
      "3344/3344 [==============================] - 1s 227us/sample - loss: 1.9038e-07 - acc: 1.0000 - mean_squared_error: 3.4617e-11\n",
      "Epoch 93/100\n",
      "3344/3344 [==============================] - 1s 204us/sample - loss: 1.7805e-07 - acc: 1.0000 - mean_squared_error: 3.1475e-11\n",
      "Epoch 94/100\n",
      "3344/3344 [==============================] - 1s 191us/sample - loss: 1.6712e-07 - acc: 1.0000 - mean_squared_error: 2.7341e-11\n",
      "Epoch 95/100\n",
      "3344/3344 [==============================] - 1s 200us/sample - loss: 1.5630e-07 - acc: 1.0000 - mean_squared_error: 2.4158e-11\n",
      "Epoch 96/100\n",
      "3344/3344 [==============================] - 1s 209us/sample - loss: 1.4651e-07 - acc: 1.0000 - mean_squared_error: 2.1202e-11 - loss: 6.1196e-08 - acc: 1.0000 - mean_squ\n",
      "Epoch 97/100\n",
      "3344/3344 [==============================] - 1s 196us/sample - loss: 1.3809e-07 - acc: 1.0000 - mean_squared_error: 1.8914e-11\n",
      "Epoch 98/100\n",
      "3344/3344 [==============================] - 1s 189us/sample - loss: 1.2911e-07 - acc: 1.0000 - mean_squared_error: 1.7046e-11\n",
      "Epoch 99/100\n",
      "3344/3344 [==============================] - 1s 189us/sample - loss: 1.2049e-07 - acc: 1.0000 - mean_squared_error: 1.4416e-11\n",
      "Epoch 100/100\n",
      "3344/3344 [==============================] - 1s 189us/sample - loss: 1.1278e-07 - acc: 1.0000 - mean_squared_error: 1.2880e-11\n",
      "1115/1115 [==============================] - 0s 324us/sample - loss: 0.2605 - acc: 0.9848 - mean_squared_error: 0.0144\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_126 (Dense)            (None, 8)                 57064     \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 57,505\n",
      "Trainable params: 57,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "3345/3345 [==============================] - 1s 357us/sample - loss: 0.5548 - acc: 0.8577 - mean_squared_error: 0.1862\n",
      "Epoch 2/100\n",
      "3345/3345 [==============================] - 1s 189us/sample - loss: 0.1134 - acc: 0.9692 - mean_squared_error: 0.0265\n",
      "Epoch 3/100\n",
      "3345/3345 [==============================] - 1s 208us/sample - loss: 0.0325 - acc: 0.9919 - mean_squared_error: 0.0068\n",
      "Epoch 4/100\n",
      "3345/3345 [==============================] - 1s 191us/sample - loss: 0.0165 - acc: 0.9952 - mean_squared_error: 0.0036\n",
      "Epoch 5/100\n",
      "3345/3345 [==============================] - 1s 188us/sample - loss: 0.0095 - acc: 0.9976 - mean_squared_error: 0.0022\n",
      "Epoch 6/100\n",
      "3345/3345 [==============================] - 1s 189us/sample - loss: 0.0050 - acc: 0.9988 - mean_squared_error: 0.0011\n",
      "Epoch 7/100\n",
      "3345/3345 [==============================] - 1s 187us/sample - loss: 0.0023 - acc: 0.9994 - mean_squared_error: 4.4696e-04\n",
      "Epoch 8/100\n",
      "3345/3345 [==============================] - 1s 188us/sample - loss: 8.6878e-04 - acc: 1.0000 - mean_squared_error: 4.4357e-05\n",
      "Epoch 9/100\n",
      "3345/3345 [==============================] - 1s 195us/sample - loss: 4.9991e-04 - acc: 1.0000 - mean_squared_error: 1.2545e-05\n",
      "Epoch 10/100\n",
      "3345/3345 [==============================] - 1s 188us/sample - loss: 3.4680e-04 - acc: 1.0000 - mean_squared_error: 7.2438e-06\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3345/3345 [==============================] - 1s 188us/sample - loss: 2.4457e-04 - acc: 1.0000 - mean_squared_error: 2.6016e-06\n",
      "Epoch 12/100\n",
      "3345/3345 [==============================] - 1s 186us/sample - loss: 1.8957e-04 - acc: 1.0000 - mean_squared_error: 1.7466e-06\n",
      "Epoch 13/100\n",
      "3345/3345 [==============================] - 1s 198us/sample - loss: 1.4950e-04 - acc: 1.0000 - mean_squared_error: 1.1555e-06\n",
      "Epoch 14/100\n",
      "3345/3345 [==============================] - 1s 263us/sample - loss: 1.1920e-04 - acc: 1.0000 - mean_squared_error: 6.6163e-07\n",
      "Epoch 15/100\n",
      "3345/3345 [==============================] - 1s 231us/sample - loss: 9.8150e-05 - acc: 1.0000 - mean_squared_error: 4.1866e-07\n",
      "Epoch 16/100\n",
      "3345/3345 [==============================] - 1s 195us/sample - loss: 8.1939e-05 - acc: 1.0000 - mean_squared_error: 2.7095e-07\n",
      "Epoch 17/100\n",
      "3345/3345 [==============================] - 1s 192us/sample - loss: 6.9495e-05 - acc: 1.0000 - mean_squared_error: 2.1963e-07\n",
      "Epoch 18/100\n",
      "3345/3345 [==============================] - 1s 265us/sample - loss: 5.9358e-05 - acc: 1.0000 - mean_squared_error: 1.5597e-07\n",
      "Epoch 19/100\n",
      "3345/3345 [==============================] - 1s 300us/sample - loss: 5.1019e-05 - acc: 1.0000 - mean_squared_error: 1.0813e-07\n",
      "Epoch 20/100\n",
      "3345/3345 [==============================] - 1s 260us/sample - loss: 4.4410e-05 - acc: 1.0000 - mean_squared_error: 9.1527e-08\n",
      "Epoch 21/100\n",
      "3345/3345 [==============================] - 1s 230us/sample - loss: 3.8784e-05 - acc: 1.0000 - mean_squared_error: 5.8621e-08\n",
      "Epoch 22/100\n",
      "3345/3345 [==============================] - 1s 199us/sample - loss: 3.4191e-05 - acc: 1.0000 - mean_squared_error: 5.2901e-08\n",
      "Epoch 23/100\n",
      "3345/3345 [==============================] - 1s 192us/sample - loss: 2.9924e-05 - acc: 1.0000 - mean_squared_error: 3.6644e-08\n",
      "Epoch 24/100\n",
      "3345/3345 [==============================] - 1s 215us/sample - loss: 2.6477e-05 - acc: 1.0000 - mean_squared_error: 2.8362e-08\n",
      "Epoch 25/100\n",
      "3345/3345 [==============================] - 1s 199us/sample - loss: 2.3196e-05 - acc: 1.0000 - mean_squared_error: 2.0617e-08\n",
      "Epoch 26/100\n",
      "3345/3345 [==============================] - 1s 195us/sample - loss: 2.0534e-05 - acc: 1.0000 - mean_squared_error: 1.4400e-08\n",
      "Epoch 27/100\n",
      "3345/3345 [==============================] - 1s 209us/sample - loss: 1.8238e-05 - acc: 1.0000 - mean_squared_error: 1.2117e-08\n",
      "Epoch 28/100\n",
      "3345/3345 [==============================] - 1s 206us/sample - loss: 1.6280e-05 - acc: 1.0000 - mean_squared_error: 8.9390e-09\n",
      "Epoch 29/100\n",
      "3345/3345 [==============================] - 1s 215us/sample - loss: 1.4610e-05 - acc: 1.0000 - mean_squared_error: 7.2122e-09\n",
      "Epoch 30/100\n",
      "3345/3345 [==============================] - 1s 192us/sample - loss: 1.3207e-05 - acc: 1.0000 - mean_squared_error: 6.1007e-09\n",
      "Epoch 31/100\n",
      "3345/3345 [==============================] - 1s 193us/sample - loss: 1.1873e-05 - acc: 1.0000 - mean_squared_error: 4.6212e-09\n",
      "Epoch 32/100\n",
      "3345/3345 [==============================] - 1s 199us/sample - loss: 1.0715e-05 - acc: 1.0000 - mean_squared_error: 3.6917e-09\n",
      "Epoch 33/100\n",
      "3345/3345 [==============================] - 1s 214us/sample - loss: 9.6802e-06 - acc: 1.0000 - mean_squared_error: 2.9259e-09\n",
      "Epoch 34/100\n",
      "3345/3345 [==============================] - 1s 203us/sample - loss: 8.7905e-06 - acc: 1.0000 - mean_squared_error: 2.4663e-09\n",
      "Epoch 35/100\n",
      "3345/3345 [==============================] - 1s 208us/sample - loss: 7.9805e-06 - acc: 1.0000 - mean_squared_error: 1.9510e-09\n",
      "Epoch 36/100\n",
      "3345/3345 [==============================] - 1s 228us/sample - loss: 7.2611e-06 - acc: 1.0000 - mean_squared_error: 1.6168e-09\n",
      "Epoch 37/100\n",
      "3345/3345 [==============================] - 1s 224us/sample - loss: 6.6504e-06 - acc: 1.0000 - mean_squared_error: 1.3565e-09\n",
      "Epoch 38/100\n",
      "3345/3345 [==============================] - 1s 238us/sample - loss: 6.0556e-06 - acc: 1.0000 - mean_squared_error: 1.0659e-09\n",
      "Epoch 39/100\n",
      "3345/3345 [==============================] - 1s 222us/sample - loss: 5.5332e-06 - acc: 1.0000 - mean_squared_error: 8.9862e-10\n",
      "Epoch 40/100\n",
      "3345/3345 [==============================] - 1s 200us/sample - loss: 5.0876e-06 - acc: 1.0000 - mean_squared_error: 7.7007e-10\n",
      "Epoch 41/100\n",
      "3345/3345 [==============================] - 1s 203us/sample - loss: 4.6516e-06 - acc: 1.0000 - mean_squared_error: 6.3058e-10\n",
      "Epoch 42/100\n",
      "3345/3345 [==============================] - 1s 281us/sample - loss: 4.2703e-06 - acc: 1.0000 - mean_squared_error: 5.1667e-10\n",
      "Epoch 43/100\n",
      "3345/3345 [==============================] - 1s 254us/sample - loss: 3.9230e-06 - acc: 1.0000 - mean_squared_error: 4.4858e-10\n",
      "Epoch 44/100\n",
      "3345/3345 [==============================] - 1s 199us/sample - loss: 3.6114e-06 - acc: 1.0000 - mean_squared_error: 3.6427e-10\n",
      "Epoch 45/100\n",
      "3345/3345 [==============================] - 1s 255us/sample - loss: 3.3288e-06 - acc: 1.0000 - mean_squared_error: 3.1955e-10\n",
      "Epoch 46/100\n",
      "3345/3345 [==============================] - 1s 218us/sample - loss: 3.0659e-06 - acc: 1.0000 - mean_squared_error: 2.6397e-10\n",
      "Epoch 47/100\n",
      "3345/3345 [==============================] - 1s 199us/sample - loss: 2.8274e-06 - acc: 1.0000 - mean_squared_error: 2.2361e-10\n",
      "Epoch 48/100\n",
      "3345/3345 [==============================] - 1s 196us/sample - loss: 2.6058e-06 - acc: 1.0000 - mean_squared_error: 1.8766e-10\n",
      "Epoch 49/100\n",
      "3345/3345 [==============================] - 1s 214us/sample - loss: 2.4138e-06 - acc: 1.0000 - mean_squared_error: 1.6003e-10\n",
      "Epoch 50/100\n",
      "3345/3345 [==============================] - 1s 205us/sample - loss: 2.2275e-06 - acc: 1.0000 - mean_squared_error: 1.3684e-10\n",
      "Epoch 51/100\n",
      "3345/3345 [==============================] - 1s 201us/sample - loss: 2.0602e-06 - acc: 1.0000 - mean_squared_error: 1.1642e-10\n",
      "Epoch 52/100\n",
      "3345/3345 [==============================] - 1s 201us/sample - loss: 1.9094e-06 - acc: 1.0000 - mean_squared_error: 9.8456e-11\n",
      "Epoch 53/100\n",
      "3345/3345 [==============================] - 1s 202us/sample - loss: 1.7669e-06 - acc: 1.0000 - mean_squared_error: 8.5416e-11\n",
      "Epoch 54/100\n",
      "3345/3345 [==============================] - 1s 200us/sample - loss: 1.6385e-06 - acc: 1.0000 - mean_squared_error: 7.3112e-11\n",
      "Epoch 55/100\n",
      "3345/3345 [==============================] - 1s 211us/sample - loss: 1.5205e-06 - acc: 1.0000 - mean_squared_error: 6.2043e-11\n",
      "Epoch 56/100\n",
      "3345/3345 [==============================] - 1s 217us/sample - loss: 1.4092e-06 - acc: 1.0000 - mean_squared_error: 5.3292e-11\n",
      "Epoch 57/100\n",
      "3345/3345 [==============================] - 1s 234us/sample - loss: 1.3063e-06 - acc: 1.0000 - mean_squared_error: 4.6044e-11\n",
      "Epoch 58/100\n",
      "3345/3345 [==============================] - 1s 210us/sample - loss: 1.2160e-06 - acc: 1.0000 - mean_squared_error: 4.0198e-11\n",
      "Epoch 59/100\n",
      "3345/3345 [==============================] - 1s 200us/sample - loss: 1.1283e-06 - acc: 1.0000 - mean_squared_error: 3.4656e-11\n",
      "Epoch 60/100\n",
      "3345/3345 [==============================] - 1s 197us/sample - loss: 1.0487e-06 - acc: 1.0000 - mean_squared_error: 2.9651e-11\n",
      "Epoch 61/100\n",
      "3345/3345 [==============================] - 1s 197us/sample - loss: 9.7554e-07 - acc: 1.0000 - mean_squared_error: 2.5925e-11\n",
      "Epoch 62/100\n",
      "3345/3345 [==============================] - 1s 191us/sample - loss: 9.0822e-07 - acc: 1.0000 - mean_squared_error: 2.2157e-11\n",
      "Epoch 63/100\n",
      "3345/3345 [==============================] - 1s 194us/sample - loss: 8.4465e-07 - acc: 1.0000 - mean_squared_error: 1.9173e-11\n",
      "Epoch 64/100\n",
      "3345/3345 [==============================] - 1s 190us/sample - loss: 7.8628e-07 - acc: 1.0000 - mean_squared_error: 1.6671e-11 - loss: 7.2071e-07 - acc: 1.0000 - mean_s\n",
      "Epoch 65/100\n",
      "3345/3345 [==============================] - 1s 200us/sample - loss: 7.3263e-07 - acc: 1.0000 - mean_squared_error: 1.4450e-11\n",
      "Epoch 66/100\n",
      "3345/3345 [==============================] - 1s 203us/sample - loss: 6.8194e-07 - acc: 1.0000 - mean_squared_error: 1.2594e-11\n",
      "Epoch 67/100\n",
      "3345/3345 [==============================] - 1s 192us/sample - loss: 6.3609e-07 - acc: 1.0000 - mean_squared_error: 1.0983e-11\n",
      "Epoch 68/100\n",
      "3345/3345 [==============================] - 1s 192us/sample - loss: 5.9443e-07 - acc: 1.0000 - mean_squared_error: 9.6136e-12\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3345/3345 [==============================] - 1s 240us/sample - loss: 5.5200e-07 - acc: 1.0000 - mean_squared_error: 8.2643e-12\n",
      "Epoch 70/100\n",
      "3345/3345 [==============================] - 1s 242us/sample - loss: 5.1465e-07 - acc: 1.0000 - mean_squared_error: 7.0882e-12\n",
      "Epoch 71/100\n",
      "3345/3345 [==============================] - 1s 232us/sample - loss: 4.8070e-07 - acc: 1.0000 - mean_squared_error: 6.2958e-12\n",
      "Epoch 72/100\n",
      "3345/3345 [==============================] - 1s 252us/sample - loss: 4.4834e-07 - acc: 1.0000 - mean_squared_error: 5.4678e-12\n",
      "Epoch 73/100\n",
      "3345/3345 [==============================] - 1s 254us/sample - loss: 4.1838e-07 - acc: 1.0000 - mean_squared_error: 4.7773e-12\n",
      "Epoch 74/100\n",
      "3345/3345 [==============================] - 1s 253us/sample - loss: 3.9097e-07 - acc: 1.0000 - mean_squared_error: 4.2106e-12\n",
      "Epoch 75/100\n",
      "3345/3345 [==============================] - 1s 341us/sample - loss: 3.6497e-07 - acc: 1.0000 - mean_squared_error: 3.6705e-12\n",
      "Epoch 76/100\n",
      "3345/3345 [==============================] - 1s 330us/sample - loss: 3.4138e-07 - acc: 1.0000 - mean_squared_error: 3.2260e-12\n",
      "Epoch 77/100\n",
      "3345/3345 [==============================] - 1s 325us/sample - loss: 3.1847e-07 - acc: 1.0000 - mean_squared_error: 2.8044e-12\n",
      "Epoch 78/100\n",
      "3345/3345 [==============================] - 1s 274us/sample - loss: 2.9771e-07 - acc: 1.0000 - mean_squared_error: 2.4604e-12\n",
      "Epoch 79/100\n",
      "3345/3345 [==============================] - 1s 274us/sample - loss: 2.7843e-07 - acc: 1.0000 - mean_squared_error: 2.1571e-12\n",
      "Epoch 80/100\n",
      "3345/3345 [==============================] - 1s 223us/sample - loss: 2.6020e-07 - acc: 1.0000 - mean_squared_error: 1.8712e-12\n",
      "Epoch 81/100\n",
      "3345/3345 [==============================] - 1s 220us/sample - loss: 2.4322e-07 - acc: 1.0000 - mean_squared_error: 1.6542e-12\n",
      "Epoch 82/100\n",
      "3345/3345 [==============================] - 1s 196us/sample - loss: 2.2751e-07 - acc: 1.0000 - mean_squared_error: 1.4527e-12\n",
      "Epoch 83/100\n",
      "3345/3345 [==============================] - 1s 191us/sample - loss: 2.1286e-07 - acc: 1.0000 - mean_squared_error: 1.2652e-12\n",
      "Epoch 84/100\n",
      "3345/3345 [==============================] - 1s 194us/sample - loss: 1.9941e-07 - acc: 1.0000 - mean_squared_error: 1.1226e-12\n",
      "Epoch 85/100\n",
      "3345/3345 [==============================] - 1s 212us/sample - loss: 1.8617e-07 - acc: 1.0000 - mean_squared_error: 9.7252e-13\n",
      "Epoch 86/100\n",
      "3345/3345 [==============================] - 1s 214us/sample - loss: 1.7426e-07 - acc: 1.0000 - mean_squared_error: 8.5911e-13\n",
      "Epoch 87/100\n",
      "3345/3345 [==============================] - 1s 215us/sample - loss: 1.6350e-07 - acc: 1.0000 - mean_squared_error: 7.6104e-13\n",
      "Epoch 88/100\n",
      "3345/3345 [==============================] - 1s 206us/sample - loss: 1.5311e-07 - acc: 1.0000 - mean_squared_error: 6.7289e-13\n",
      "Epoch 89/100\n",
      "3345/3345 [==============================] - 1s 199us/sample - loss: 1.4338e-07 - acc: 1.0000 - mean_squared_error: 5.8692e-13\n",
      "Epoch 90/100\n",
      "3345/3345 [==============================] - 1s 191us/sample - loss: 1.3446e-07 - acc: 1.0000 - mean_squared_error: 5.2128e-13\n",
      "Epoch 91/100\n",
      "3345/3345 [==============================] - 1s 193us/sample - loss: 1.2581e-07 - acc: 1.0000 - mean_squared_error: 4.5952e-13\n",
      "Epoch 92/100\n",
      "3345/3345 [==============================] - 1s 197us/sample - loss: 1.1788e-07 - acc: 1.0000 - mean_squared_error: 4.0413e-13\n",
      "Epoch 93/100\n",
      "3345/3345 [==============================] - 1s 197us/sample - loss: 1.1060e-07 - acc: 1.0000 - mean_squared_error: 3.5881e-13\n",
      "Epoch 94/100\n",
      "3345/3345 [==============================] - 1s 201us/sample - loss: 1.0370e-07 - acc: 1.0000 - mean_squared_error: 3.2132e-13\n",
      "Epoch 95/100\n",
      "3345/3345 [==============================] - 1s 200us/sample - loss: 9.7368e-08 - acc: 1.0000 - mean_squared_error: 2.8026e-13\n",
      "Epoch 96/100\n",
      "3345/3345 [==============================] - 1s 199us/sample - loss: 9.1256e-08 - acc: 1.0000 - mean_squared_error: 2.4932e-13\n",
      "Epoch 97/100\n",
      "3345/3345 [==============================] - 1s 199us/sample - loss: 8.5629e-08 - acc: 1.0000 - mean_squared_error: 2.2081e-13\n",
      "Epoch 98/100\n",
      "3345/3345 [==============================] - 1s 200us/sample - loss: 8.0368e-08 - acc: 1.0000 - mean_squared_error: 1.9653e-13\n",
      "Epoch 99/100\n",
      "3345/3345 [==============================] - 1s 198us/sample - loss: 7.5444e-08 - acc: 1.0000 - mean_squared_error: 1.7371e-13\n",
      "Epoch 100/100\n",
      "3345/3345 [==============================] - 1s 211us/sample - loss: 7.0905e-08 - acc: 1.0000 - mean_squared_error: 1.5647e-13\n",
      "1114/1114 [==============================] - 0s 349us/sample - loss: 0.2393 - acc: 0.9829 - mean_squared_error: 0.0163\n"
     ]
    }
   ],
   "source": [
    "def validacion(indice_entren, indice_test, X, Y):\n",
    "    \n",
    "    X_train = X[indice_entren]\n",
    "    X_test = X[indice_test]\n",
    "    Y_train = Y.iloc[indice_entren]\n",
    "    Y_test = Y.iloc[indice_test]\n",
    "        \n",
    "    model = keras.Sequential()\n",
    "    ## Adiciona las capas\n",
    "    for j in range(0,cresults[0]):\n",
    "        model.add(keras.layers.Dense(units =nresults[0], activation=tf.nn.relu, input_dim = X_train.shape[1]))\n",
    "    model.add(keras.layers.Dense(units = 1, activation=tf.nn.sigmoid))\n",
    "    \n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc','mse']\n",
    "              )\n",
    "## Estructura del modelo creado\n",
    "    model.fit(X_train,Y_train,epochs=100,batch_size=30)\n",
    "    r = model.evaluate(X_test, Y_test)\n",
    "\n",
    "            \n",
    "    return r[2]\n",
    "    \n",
    "kf = KF(n_splits=4)\n",
    "\n",
    "crossval = []\n",
    "for indice_entren, indice_test in kf.split(X_train):\n",
    "    crossval.append(validacion(indice_entren,indice_test, X_train, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MSE promedio de la validación cruzada:  0.01914374204352498\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"MSE promedio de la validación cruzada: \", sum(crossval)/len(crossval))    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Copia de Untitled3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
